Index: app.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\nimport logging\nimport os\nfrom flask import Flask,  jsonify, Response, stream_with_context\nfrom flask_cors import CORS\nfrom document_retriever import my_retriever\nfrom error_handler import register_error_handlers\nfrom openai import OpenAIError\nfrom werkzeug.exceptions import BadRequest\nfrom conversation_history import save_conversation, history\nfrom pymongo import MongoClient\nfrom utils import get_request_data, topic_classification, handle_weather_topic, handle_trans_topic, handle_else_topic, text_chatgpt\nfrom mongo_client import get_mongo_client\nimport json, time\n\n\n\n# 플라스크 앱 정의\napp = Flask(__name__)\nCORS(app)\nregister_error_handlers(app) # flask error handler 등록\n\n# 로깅 설정\nlogging.basicConfig(\n    filename='./logging/error_log.log',\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    datefmt='%Y-%m-%d %H:%M:%S'\n)\n\n# 환경 변수에서 MongoDB 연결 URL 가져오기\n# mongo_uri = os.getenv('MONGO_URI')\nclient, db, collection = get_mongo_client()\n\n\n\n# 환경 변수에서 API 키와 PDF 경로를 로드\nOPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\nTMAP_API_KEY = os.getenv('TMAP_API_KEY')\nKAKAO_MAP_API_KEY = os.getenv('KAKAO_MAP_API_KEY1')\nWEATHER_API_KEY = os.getenv('WEATHER_API_KEY')\nLOCATION1 = os.getenv('LOCATION1')\n\n# LLM 변수 정의\nSTREAM_TOKEN_SIZE = 1 # 스트림 토큰 단위 default 125\nMODEL_VERSION = \"gpt-4o-mini\" # \"gpt-3.5-turbo\"\nMAX_TOKENS_OUTPUT = 500\n\n# 검색할 문서 로드\nfile_path = os.getenv('PDF_PATH', 'data/ktb_data_09.md')\ntry:\n    retriever, faiss_db = my_retriever(file_path)\nexcept OpenAIError as e:\n    raise e\nprint(\"=======검색기 로드 끝========\")\n\n# 모델의 응답을 스트리밍하기 위한 제너레이터 함수\ndef generate_response_stream(user_id, chat_id, user_input):\n    my_history = history(collection, user_id, chat_id, limit=4) # 최근 것부터 불러움?\n    # Construct the context for the LLM by passing the history along with the prompt\n    context = []\n    context.append({\"role\": 'user', \"content\": user_input})\n    for h in reversed(my_history):\n        context.append({\"role\": h[\"role\"], \"content\": h[\"text\"]})\n    \n    print(\"===\"*10)\n    for ele in context:\n        print(ele)\n    print(\"===\"*10)\n\n    print(\"원래 사용자 인풋:\\n\", user_input, \"=\"*10)\n    print(\"히스토리 프롬프트:\\n\", context, \"=\"*10)\n\n    #input_txt = user_input + history_prompt\n    # retriever의 스트리밍 응답을 처리 (pipeline.stream 사용)\n    save_conversation(collection, user_id, chat_id, \"user\", user_input) #사용자 질문\n    answer_text = ''\n    for chunk in retriever.stream(context):  # stream을 사용하여 스트리밍 처리\n        print(\"chunk:\", chunk)\n        answer_text += chunk\n        chunk_json = json.dumps({\"text\": chunk}, ensure_ascii=False)\n        yield f\"data: {chunk_json}\\n\\n\" # \"data\": ... \\n\\n 을 \n        # print(chunk)\n    # 질문 & 응답 저장 \n    \n    #time.sleep(0.1)\n    save_conversation(collection, user_id, chat_id, \"system\", answer_text) # 답변 \n    print(\"최종 답변:\", answer_text)\n\n@app.route(\"/nlp-api/conv\", methods=['POST'])\ndef llm():\n    params = get_request_data() # request body 를 가져옴\n    user_input, user_id, chat_id = params['content'], params['user_id'], params['chat_id']\n    print(\"user_input, user_id, chat_id:\", user_input, user_id, chat_id)\n\n    #save_conversation(collection, user_id, chat_id, \"user\", user_input)\n\n    response_generator = generate_response_stream(user_id, chat_id, user_input)\n    return Response(stream_with_context(response_generator), mimetype='text/event-stream', )\n    #return Response(stream_message(response_generator), mimetype='application/json')\n\n@app.route(\"/nlp-api/title\", methods=['POST'])\ndef make_title(): # 대화의 타이틀 생성\n    params = get_request_data(title=True)\n    user_input = params['content']\n    system_prompt = \"\"\"넌 대화 타이틀을 만드는 역할이야. 챗봇에서 사용자의 첫 번째 메시지를 기반으로 해당 대화의 제목을 요약해줘.\"\"\"\n    title = text_chatgpt(system_prompt, user_input)\n\n    if title is None:\n        return jsonify({\"error\": \"죄송해요. 챗 지피티가 제목을 제대로 가져오지 못했어요.\"})\n    title = title.strip('\"') # 앞뒤의 큰 따옴표 제거\n    return jsonify({\"title\": title})\n\n@app.route(\"/nlp-api/test\", methods=['POST'])\ndef test(): # whole text 만든 다음, 청크 단위로 나눠 스트림 형식으로 전달\n    params = get_request_data() # request body 를 가져옴\n    user_input, user_id, chat_id = params['content'], params['user_id'], params['chat_id']\n    system_prompt = \"\"\"사용자의 질문에 친절하게 대답해줘.\"\"\"\n    result = text_chatgpt(system_prompt, user_input)\n    print(\"result(whole text):\", result)\n    response_generator = generate_response_stream(user_id, chat_id, user_input)\n    return Response(response_generator, mimetype='text/event-stream')\n\n@app.route(\"/nlp-api/test/stream\", methods=['POST'])\ndef stream_output(): # chatGPT API 에서 실시간으로 청크 단위로 답변을 받아옴.\n    #user_input, user_id, chat_id = get_request_data()  # 공통\n    params = get_request_data() # request body 를 가져옴\n    user_input, user_id, chat_id = params['content'], params['user_id'], params['chat_id']\n\n    # 답변 가져오기\n    response_generator = generate_response_stream(user_id, chat_id, user_input)\n    return Response(response_generator, mimetype='text/event-stream')\n\n# test function for error handling\n@app.route(\"/nlp-api/error_handling\", methods=['POST'])\ndef error_handle(): # 대화의 타이틀 생성 #(params)\n    params = get_request_data() # request body 를 가져옴\n    if not params : # json = {}\n        raise BadRequest(\"No request body\")\n    elif 'content' not in params or not params['content'].strip(): # json = {'msg': \"...\"} or json = {'content': \"\"}\n        raise BadRequest(\"No content field in request body or value for content is empty\")\n    return jsonify({\"result\": f\"no error:{params['content']}\"})\n\n\n\nif __name__ == '__main__':\n    print(\"app starts running\")\n    app.run(port=5001,debug=True)
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app.py b/app.py
--- a/app.py	(revision 0a6116d258dbb8c406e2851953ea33c3cdd8e691)
+++ b/app.py	(date 1727341925312)
@@ -11,7 +11,7 @@
 from pymongo import MongoClient
 from utils import get_request_data, topic_classification, handle_weather_topic, handle_trans_topic, handle_else_topic, text_chatgpt
 from mongo_client import get_mongo_client
-import json, time
+import json
 
 
 
@@ -56,35 +56,36 @@
 
 # 모델의 응답을 스트리밍하기 위한 제너레이터 함수
 def generate_response_stream(user_id, chat_id, user_input):
-    my_history = history(collection, user_id, chat_id, limit=4) # 최근 것부터 불러움?
-    # Construct the context for the LLM by passing the history along with the prompt
-    context = []
-    context.append({"role": 'user', "content": user_input})
-    for h in reversed(my_history):
-        context.append({"role": h["role"], "content": h["text"]})
-    
-    print("==="*10)
-    for ele in context:
-        print(ele)
-    print("==="*10)
+    my_history = history(collection, user_id, chat_id, limit=4)
+
+    history_prompt = ""
+    if len(my_history) >  0: # 기존 대화 내역이 있음. 
 
+        #history_prompt = "이 질문에 답변하는데, 다음의 기존 대화 내역과 연관이 있으면, 다음의 기존 대화 내역을 참고해줘. 기존 대화 내역: \n```"
+
+        history_prompt = """
+                        When answering this question, refer to the existing conversation history below if needed.\n",
+                        "If the conversation history is not relevant or helpful for this question, proceed without referencing it.\n",
+                        "existing conversation history: ```
+                        """
+        for h in my_history:
+            history_prompt +=  h['role']+":"+h['text']+"\n"
+        history_prompt += '```'
     print("원래 사용자 인풋:\n", user_input, "="*10)
-    print("히스토리 프롬프트:\n", context, "="*10)
+    print("히스토리 프롬프트:\n", history_prompt, "="*10)
 
-    #input_txt = user_input + history_prompt
+    input_txt = user_input + history_prompt
     # retriever의 스트리밍 응답을 처리 (pipeline.stream 사용)
-    save_conversation(collection, user_id, chat_id, "user", user_input) #사용자 질문
     answer_text = ''
-    for chunk in retriever.stream(context):  # stream을 사용하여 스트리밍 처리
+    for chunk in retriever.stream(input_txt):  # stream을 사용하여 스트리밍 처리
         print("chunk:", chunk)
         answer_text += chunk
         chunk_json = json.dumps({"text": chunk}, ensure_ascii=False)
         yield f"data: {chunk_json}\n\n" # "data": ... \n\n 을 
         # print(chunk)
     # 질문 & 응답 저장 
-    
-    #time.sleep(0.1)
-    save_conversation(collection, user_id, chat_id, "system", answer_text) # 답변 
+    save_conversation(collection, user_id, chat_id, "user", user_input)
+    save_conversation(collection, user_id, chat_id, "system", answer_text)
     print("최종 답변:", answer_text)
 
 @app.route("/nlp-api/conv", methods=['POST'])
@@ -119,7 +120,7 @@
     result = text_chatgpt(system_prompt, user_input)
     print("result(whole text):", result)
     response_generator = generate_response_stream(user_id, chat_id, user_input)
-    return Response(response_generator, mimetype='text/event-stream')
+    return Response(stream_message(response_generator), mimetype='text/event-stream')
 
 @app.route("/nlp-api/test/stream", methods=['POST'])
 def stream_output(): # chatGPT API 에서 실시간으로 청크 단위로 답변을 받아옴.
@@ -129,7 +130,7 @@
 
     # 답변 가져오기
     response_generator = generate_response_stream(user_id, chat_id, user_input)
-    return Response(response_generator, mimetype='text/event-stream')
+    return Response(stream_message(response_generator), mimetype='text/event-stream')
 
 # test function for error handling
 @app.route("/nlp-api/error_handling", methods=['POST'])
Index: data/ktb_data_09.md
===================================================================
diff --git a/data/ktb_data_09.md b/data/ktb_data_09.md
deleted file mode 100644
--- a/data/ktb_data_09.md	(revision 0a6116d258dbb8c406e2851953ea33c3cdd8e691)
+++ /dev/null	(revision 0a6116d258dbb8c406e2851953ea33c3cdd8e691)
@@ -1,501 +0,0 @@
-# Title : 카카오 클라우드 교육 채널 로그인 안내
-
-1. **카카오 계정 등록 안내**:
-
-\- 여러분이 제출한 카카오 계정이 카카오 클라우드 교육 채널에 등록되었습니다.
-
-2. **로그인 방법**:
-
-\- **로그인 링크**: [카카오테크 부트캠프 바로가기](https://krampoline.kakao.com/) - **로그인 절차**: 제공된 링크로 접속하여 본인의 카카오 계정으로 로그인합니다.
-
-# Title : 카카오 클라우드 교육 안내
-
-일정 및 내용:
-
-1. 기간: 8/6(화)-8/13(화)(6일)
-2. 시간: 09:00-18:00
-3. 장소: 온라인(Zoom 강의실)
-4. 오프라인(판교 카카오테크 부트캠프)
-5. 주제: 카카오 클라우드 및 생성형AI, 크램폴린IDE 6. 방식: 이론 강의 및 실습
-
-# Title : 카카오테크 부트캠프 오시는 길
-
-주차 지원 : 주차 지원이 불가하오니 꼭 대중교통 이용을 부탁드립니다.
-카카오 맵 : https://place.map.kakao.com/492743367?referrer=daumsearch_local. 상세 주소 : 경기 성남시 분당구 대왕판교로 660 유스페이스1 A동 405호
-
-대중 교통 :
-
-0. 판교역 4번 출구 기준 출발.
-1. 승차: 판교역 서편 정류장 375,380 버스 승차.
-2. 하차: 메디포스트 정류장 하차 (2개 정류장 이동). 3. 입구: 유스페이스몰 1 A동까지 도보로 3분 이동
-
-# Title : Chat GPT Plus 지원 안내 및 방법
-
-### ChatGPT Plus 지원 안내 요약 1. **지원 대상**:
-
-\- **교육 기간**: ChatGPT Plus, ChatGPT API, Claude, Colab Pro+ 구독료 지원
-\- **지원 횟수**: ChatGPT Plus or ChatGPT API or Claude (총 6회), Colab Pro+ (총 5회)
-
-2. **지원 신청 방법**:
-
-\- **신청 기한**: 2024년 8월 6일(화) 오후 3시까지
-
-\- **신청 방법**: 아래 제공된 구글폼 링크를 통해 구독료 지원 신청서 제출
-
-3. **구독료 청구 방법**:
-
-\- **지원 항목**: ChatGPT Plus or ChatGPT API or Claude (월 20$ 상당)
-\- **청구 서류**: 7월 결제 건에 대한 카드 매출전표 (결제일자, 결제처, 달러($), 원화(₩) 금 액 포함)
-\- **제출 방식**: 모든 증빙자료는 PDF로 합쳐 하나의 파일로 제출
-
-\- **제출 파일명**: ex. ella.lee(이지은)\_인공지능1회차\_7월
-
-\- **중복 지원 불가**: Colab Pro+ 7월 구독료와 AWS 7월 사용료 중복 지원 불가
-
-4. **유의사항**:
-
-\- **환급 불가 조건**: 2024년 7월에 결제하지 않은 경우, 다른 요금제로 결제한 경우 환급 불가
-\- **제출 기한 준수**: 8월 6일(화) 오후 3시까지 제출 필수
-
-# Title : 인프런 강의 지원
-
-지원 목적 : 여러분의 원활한 학습을 위하여 인프런 강의가 지원됩니다. 지원 내용 : 인프런 크레딧 100,000원.(추가 지원 예정은 없으나)
-지원 방식 : 제출한 인프런 계정으로 로그인 후 자유롭게 수강신청. 주의 사항 :
-
-1. 제출한 계정으로만 수강신청이 가능합니다.
-2. 부여된 크레딧에 개인 비용을 더하여 강의를 구매할 수는 없습니다. 개인 비용에 대한 정 산이 불가능한 구조인 점 양해 부탁드립니다.
-3. 수강신청 기간은 교육 기간 내 자유롭게 가능합니다. (월별 수강신청 기간이 매월 1일~ 말일로 표기된 부분은 매월 상시로 가능하다는 뜻으로 이해해주시면 됩니다.)
-4. 강의 구매 시 10% 할인 금액이 적용됩니다. 비즈니스 그룹의 경우 일괄 적용되는 할인율 이기 때문에 개인이 구매하는 경우보다 금액이 높을 수 있습니다. 이 점 고려하셔서 계획적 으로 강의 구매하시면 좋을 것 같습니다 .
-5. 현재는 제한 없이 어떤 강의든 수강신청이 가능합니다. 학습에 꼭 필요한 강의로 잘 골라 주세요.
-
-# Title : 사원증 배부 안내
-
-일정 : 24. 08. 23.(금) 오후 4시부터
-장소 : 카카오테크 부트캠프 강의장 사무실(GOORMEE 1)
-
-# Title : 지문 등록 안내
-
-9월 2일(월)로 일정을 변경하고자 합니다. 미등록 지문자 교육생 분들은 일정 참고 부탁드립니다!!
-
-# Title : 8월 교육(강의) 일정 안내
-
-**8월 교육(강의) 일정**:
-
-1. **7/31(수) ~ 8/5(월)**: 클라우드 관련 강의
-2. **8/6(화) ~ 8/13(화)**: 카카오 클라우드 관련 강의 3. **8/14(수) ~ 8/30(월)**: 팀 미션 진행
-3. **8/23(금)**: 코딩테스트, 특강, 네트워킹
-
-# Title : 팀 미션 세부 내용
-
-팀 미션 내용 : 구름 EXP 미션 중 1개를 선정하여 진행.
-기간 : 8/1(목) ~8/2(금) : 주제 선정 및 노션 팀 미션 페이지 작성. (예시)팀 미션 페이지 (ht tps://goormkdx.notion.site/cbe8d0e2f73a411e829c41cd6aeb85a6?pvs=4).
-팀별 프로젝트 수행 결과 보고서 제출: 9/10(화) 오후 11시 59분까지
-결과 보고서 검토 및 우수팀 발표: 9/11(수)
-오프라인 우수팀 결과물 발표: 9/12(목)~9/13(금)
-
-사유 : 9/4~ 9/7 (KTB)해커톤 일정이 잡혀있어서 집중을 위해 연기.
-
-# Title : 인공지능 커리큘럼 변경 안내(교육시간)
-
-선도기업 카카오는 여러분들께 더 많은 프로젝트 경험 제공 및 개인 포트폴리오 강화를 위 해 프로젝트 비율을 높여 커리큘럼을 편성하였습니다. 이에 따라 부족한 이론을 위해 인프 런 강의 제공과 8월부터 카카오 멘토분들이 배정될 예정입니다. 인공지능 과정: 364시간 -> 784시간.
-
-# Title : 방학
-
-• 광복절08.15.(목)
-• 휴강09.09.(월)
-• 추석09.16.(월), 09.17.(화), 09.18.(수) • 개천절10.03.(목)
-• 휴강10.04.(금), 10.07.(월), 10.08.(화) • 한글날10.09.(수)
-• 휴강10.10.(목), 10.11.(금)
-• 휴강12.23.(월), 12.24.(화)
-• 성탄절12.25.(수)
-• 일요일
-
-# Title : 교육 중도 포기 안내
-
-중도포기 신청 전 안내사항: 원칙적으로 교육생은 K-Digital Training 과정에 1회만 참여가 가능합니다. 따라서 본 과정 중도 포기 시 추후 구름을 포함한 다른 교육 기관에서 실시하 는 K-Digital Training 교육에 참여할 수 없게 됩니다. 국민내일배움카드 사용에 불이익이 있 을 수 있으며 자세한 사항은 관할 고용 센터로 문의해주시기 바랍니다.
-
-포기사유가 취업일 경우 : 취업확인서를 함께 작성합니다. 사업장 (인)에는 회사 직인을 첨 부해주세요. 중도포기서 작성 시 ‘참여과정’과 ‘포기사유’란에는 해당하는 부분에 체크 표시 를 하고, 참여기간도 작성합니다.
-
-중도포기서 양식 제출 전, 반드시 과정 담당 관리자와 사전에 공유가 완료되어야 합니다. 작 성하신 중도포기일 포함 이후 훈련에 참여한 이력이 사라집니다. 신중하게 일정 확인 후, 작 성해 주시기 바랍니다. PDF 파일 양식을 사용하는 경우, 워드 파일에 기재되어 있는 작성 방법을 참고하여 올바르게 작성해주시기 바랍니다. (참여 회차 및 훈련기간, 중도포기일 작 성 양식 준수 필수)
-
-제출 방법 : 작성한 중도포기서(+ 취업확인서)의 PDF 또는 원본 파일을 통합신청센터를 통 해 제출합니다. 통합신청센터 → 중도 포기 신청 → 서류 첨부
-중도 포기서 양식 : https://goormkdx.notion.site/ca0d305314b249a39ce7e0ce41737ba5 에서 확인 가능
-
-# Title : 중도탈락 또는 제적 시 페널티
-
-\### 국민내일배움카드 운영 규정을 따름.
-
-1. **중도탈락 및 제적 시 페널티**:
-
-\- **1회**: 국민내일배움카드 **지원한도액 20만원 차감** - **2회**: 국민내일배움카드 **지원한도액 50만원 차감** - **3회**: 국민내일배움카드 **지원한도액 100만원 차감**
-
-2. **부정출결(대리출석)**:
-
-\- **즉시 제적**: 국민내일배움카드 **지원한도액 전액 차감** 및 **수강 제한**
-
-3. **조기취업 시**:
-
-\- **미수료 처리**: 페널티 없음
-\- **수료 인정 조건**: **출석률 80% 이상** 시 중도포기하더라도 수료로 인정, 페널티
-
-없음
-_중요_: 중도포기나 제적 시, 국민내일배움카드의 지원 한도액이 차감되며, 부정출결의 경우 즉시 제적 처리되고 지원한도액 전액이 차감됩니다. 조기취업 시에는 미수료로 처리되지만 페널티가 적용되지 않으며, 출석률이 80% 이상일 경우 수료로 인정됩니다.
-
-# Title : 훈련 장려금 지급
-
-1. **훈련 장려금 기준**:
-
-\- 출석율 80% 이상: **최대 116,000원** (일 5,800원)
-\- 출석율 80% 미만: **미지급**
-
-2. **K-디지털 트레이닝 특별훈련수당**:
-
-\- 출석율 80% 이상: **최대 200,000원**
-\- 출석율 80% 미만: **미지급** - 결석 시: 1일 결석마다 **1만 원** 차감 3. **총 합계**: - 1일 출석 시: **15,800원** (훈련장려금 + 특별훈련수당) - **계산식**: 출석일수 X 15,800원
-_중요_: 출석율 80% 이상을 유지해야 최대 혜택을 받을 수 있습니다.
-
-훈련 장려금 진행 순서
-
-1. 단위기간 종료 이후 출석 정정 신청 - 출석은 훈련 장려금과 연관되어 있기 때문에 출석 정정을 할 수 있는 기간을 제공 - 소요일: 1주.
-2. 출석 이의 신청한 내용 확인 - 증빙 자료 및 출석 데이터 확인 업무 등 - 소요일: 2 ~ 3일.
-3. 고용센터 출석 정정 공문 요청 및 처리 - 출석 정정 건에 대한 수정 요청은 공문 을 통해 요청 및 처리 진행 - 소요일: 2 ~ 4일.
-4. 훈련 장려금 지급 신청 - 훈련기관이 훈련 장려금 지급 요청을 대리로 신청 - 소 요일: 1일.
-5. 고용센터 처리 및 훈련 장려금 지급 - 대리 신청한 훈련 장려금 내용 확인 및 고 용센터에서 훈련 장려금 지급 진행 - 소요일: 최소 2주 ~ 1달.
-
-# Title : 출석
-
-기준 : 출결은 교육 수료 조건 중 하나이자, 훈련장려금을 받는 기준으로 활용됩니다. 출석 방법과 관련 기준을 숙지하고 교육기간 내내 꼼꼼하게 관리해주시기 바랍니다.
-
-정상 출석: 일 8시간 교육 참여.
-결석: 지각, 외출, 조퇴 등으로 인해 일 4시간 미만 교육 참여 (점심시간 제외).
-지각: 오전 09:10 이후 출석체크 했을 경우. 외출: 교육시간 중간에 일정 시간 동안 참여가 불가한 경우.(오전 09:10 이전에 출결하면 지각이 아님)
-* 출석 인정 시간 : 오전 8시 50분 ~ 오전 9시 10분.에 출석한 경우 지각으로 처리하지 않음. 9시 11분 부터 지각
-조퇴: 교육시간 중간부터 끝까지 참여가 불가한 경우.
-전체 교육 일수의 80% 이상 출석해야 수료가 가능합니다.
-총 교육기간 중 지각, 조퇴, 외출 3회 누적 시 1일 결석 처리됩니다.
-* 계산 방법 : 지각 = 조퇴 = 외출 = 결석1/3
-* 예시
-1. 지각2회 + 조퇴3회 + 외출1회 = 지각 6회 = 결석2회
-2. 지각 1회 + 조퇴 1회 = 결석 0회(2/3회지만 내림으로 계산해서 1미만은 0, 1 이상 2 미만은 1회로 계산)
-
-출석 방법 : 입/퇴장시간은 시스템에 자동 등록되며 개인 불찰로 인한 수정이 불가합니다. 퇴장하기 미진행 시, 해당 1일은 결석 처리됩니다.
-외출 및 조퇴 : 해당 시간에 맞춰 입/퇴장 시간 기록. 외출 시에는 출석 -> 외출 출발 -> 복귀 -> 퇴실 시 총 4회 실시합니다. 조퇴 시에는 출석 → 퇴실 총 2회 실시합니다. 시스템 에 외출 및 조퇴 미입력이 적발되는 경우, 부정출결로 인해 해당 1일 결석 처리 됩니다. 하 루에 지각, 외출, 조퇴가 4시간 이상(점심시간 제외)일 경우 해당 1일은 결석 처리됩니다. 1 시간은 1교시(교육시간+쉬는시간)를 모두 포함한 시간을 뜻합니다.
-
-# Title : 출석 확인 방법
-
-## 1. 출석 현황 확인
-
-\- **HRD-Net 앱**: 본인의 출결 현황을 실시간으로 확인할 수 있습니다.
-
-## 2. 출석 인정 사유 및 신청 방법
-
-\- **관련 규정**: 국민내일배움카드 제34조 제2항 제2호 및 [별표3]에 명시된 사유에 해당 할 경우 출석 인정 가능
-
-\- **휴가 사용**: 6개월 과정 수강철회 기간 이후부터 사용 가능
-\- **시스템 오류 시**: 통합신청센터를 통해 출석 정정 신청 가능
-\- **개인 불찰**: 개인 실수로 인한 정정 신청은 불가
-
-## 3. 출석 인정 신청 절차
-
-\- **신청 기한**: 출석 인정 사유 발생 3일 전까지 통합신청센터에 신청 (질병, 경조사에 한해 당일 신청 가능)
-\- **증빙 서류**: 출석 인정을 위해 필요한 자료를 함께 제출해야 함
-\- **변경 및 취소**: 출석 인정 신청에 대한 변경 및 취소는 해당일 1일 전까지 통합신청센터를 통해 가능
-
-## 4. 통합신청센터 이용 방법
-
-\- **노션 링크**: 각 과정별 노션 페이지의 통합신청센터 바로가기 링크를 통해 이동 가능
-
-출석 입력요청대장 작성 방법 : 발생일과 신청일은 동일한 날짜로 기재해야 합니다. 사유 발 생한 날, 훈련 기관에서 일괄 신청하기 때문에 발생일 기준 날짜로 신청일도 작성해 주세요. 날짜형식 주의!! 2024.07.01. .으로 통일하여 작성하기! 사유는 출석인정사유 카테고리를 작 성해야 합니다. 훈련·시험 / 면접 / 예비군 / 결혼 / 사망 / 출산 / 질병 / 입원 / 휴가 / 훈 련직종 관련 해커톤 ·경진대회. 입실시간(외출시간)과 퇴실시간(귀원시간)은 – 로 표시합니다. 하루동안 출석인정을 승인 받는 과정이기 때문에 입실시간과 퇴실시간의 표기는 사용되지 않습니다. 훈련생 서명은 자필 서명으로 작성해야 합니다. 자필 서명이 어려울 경우, 전자 서명으로 정자체 작성해야 합니다. 증빙서류 제출 시, 출석 입력 요청 대장도 함께 작성하여 PDF 1개의 파일로 제출하기!
-
-# Title : 출석 증빙 양식
-
-휴가 신청서 양식: [KTB 노션](https://goormkdx.notion.site/8bd90e0c46f64474b56528219115 b193)에서 양식확인이 가능합니다.
-휴가 신청은 사전에 최소 3일전 까지 통합신청센터에서 합니다. 이후 신청은 휴가 반영이 불가합니다. 휴가신청은 수강철회 기간 이후부터 사용 가능합니다. 적치된 휴가 사용은 가능 하지만 다음 달 휴가를 미리 사용하는 것은 불가합니다.
-
-# Title : 출석 인정 사례
-
-질병·병가: 병가 증빙 시 어떤 증빙서류를 제출해야 하나요? 병원방문 날짜, 병원직인 필수 포함된 서류를 제출해 주셔야 합니다. 간이 진단서 및 처방전만 제출 시 적용이 불가합니다. 대학병원 진료는 진료확인서 대신 영수증 제출이 가능합니다. 치과 진료 및 피부과 시술 진 료는 적용이 불가합니다.
-
-예비군: 예비군 증빙서류는 무엇인가요? 예비군 홈페이지에서 다운로드 받은 교육필증과 출 석입력요청대장을 제출해 주셔야 합니다. (간이 확인증 및 소집필증으로는 적용이 불가합니 다). 면접: 면접 확인서 서류 내 어떤 부분이 포함되어야 하나요? 면접날짜/회사직인이 필수 로 포함되어 있어야 합니다. 면접예정안내 메일과 회사면접관 서명이 들어가 있을 경우, 적 용이 불가합니다.
-
-기타: 사설 대회 참여로 인한 출석인정도 가능한가요? 대회 참석 후 바로 채용으로 이어지 는 경우에만 소요 일수만큼 출석 인정이 가능합니다. 이후 채용의 이유로 수업 참석이 어려 울 경우 중도포기 처리됩니다.
-기타: 졸업식, 국민취업지원제도 상담 등 위에 기재되지 않은 사유는 인정이 불가한가요? 출 석 인정 사항은 행정 규칙에 의한 기준으로 위에 해당하지 않을 경우 불가합니다.
-
-# Title : 1~8교시 스케줄(시간표)
-
-1교시: 09:00 - 09:50, 쉬는시간: 09:50 - 10:00. 2교시: 10:00 - 10:50, 쉬는시간: 10:50 - 11:00. 3교시: 11:00 - 11:50, 쉬는시간: 11:50 - 12:00. 점심시간: 12:00 - 13:00.
-
-4교시: 13:00 - 13:50, 5교시: 14:00 - 14:50, 6교시: 15:00 - 15:50, 7교시: 16:00 - 16:50, 8교시: 17:00 - 18:00.
-
-쉬는시간: 13:50 - 14:00. 쉬는시간: 14:50 - 15:00. 쉬는시간: 15:50 - 16:00. 쉬는시간: 16:50 - 17:00.
-
-# Title : 자격증 응시료 과정별 지원 자격증
-
-| 풀스택               | **정보처리기사, 데이터분석전문가(ADP,ADsp,SQLD)등**                                      |
-| -------------------- | ---------------------------------------------------------------------------------------- |
-| 생성형 AI(인 공지능) | AICE, AIFB, TensorFlow Developer Certification, <br />데이터분석전문가(ADP,A Dsp,SQLD)등 |
-| 클라우드             | AWS, CKA, CKAD, CKS, KCNA 등                                                             |
-
-\* 그 외 교육 과정과 연관이 있다고 판단되는 자격증의 경우, 추가 지원이 가능합니다.
-
-자세한 내용은 지원을 희망하는 자격증 정보(명칭, 응시 정보, 비용 등)와 함께 각 회차 별 게시판을 통해 교육 운영 관리자에게 문의해주시기 바랍니다.
-
-국가기술자격증, 국가공인 민간자격증, 국제자격증 등의 경우 지원이 가능하며, PCCP와 같 은 민간 자격증은 지원이 불가합니다.
-국가공인 민간자격증 종목별 상세정보: https://www.q-net.or.kr/crf008.do?id=crf00801
-
-입금 시기
-
-교육 기간 내에 시험에 응시 및 합격한 해당 교육 과정 수료자 교육 기간
-
-수료 이후 한 달 이내
-
-| 지원 대상 | 교육 기간 내에 시험에 응시 및 합격한 해당 교육 과정 수료자          |
-| --------- | ------------------------------------------------------------------- |
-| 지원 기간 | 교육 기간                                                           |
-| 지원 내용 | 교육 기간 내 시험 응시 및 합격 후 합격증, 매출전표 제출시 전액지 원 |
-| 입금 시기 | 수료 이후 한 달 이내                                                |
-
-응시료 청구 방법 : 합격증과 매출전표를 제출해 주세요. CKA 자격증과 같은 해외 결제 건 에 대해서는 매출전표에 반드시 달러($) 금액과 함께 원화(₩) 금액이 표기되어야 합니다. 결 제 직후에는 매출전표에 달러로만 금액이 표기되지만, 결제일로부터 7일이 경과된 후에는 달러와 함께 원화로도 금액이 표기됩니다. (카드사에 따라 원화 표기까지 최대 14일이 소요 될 수 있으며 완료될 때까지 기다립니다.) 국민카드로 결제하셨나요? 국민카드는 달러/원화 가 함께 나오지 않고 다른 페이지에서 각각 조회되는 것으로 확인됩니다. 국민카드인 분들 은 달러와 원화가 각각 조회 되는 파일 2개를 모두 제출해주세요. 매출전표 예시 보기 (매 출전표 = 승인전표 = 영수증)
-
-유의사항 : 반드시 교육 기간 내 응시하여 합격한 시험만 응시료 지원이 가능합니다. 필기, 실기 또는 1차, 2차 등 최종 합격까지 단계가 나뉘어진 경우 최종 합격이 확인된 자격증에 한해서만 지원이 가능합니다. (필기만 합격 시 지원 불가). 해당 교육을 수료하신 분들을 대 상으로 지원되는 항목입니다. (미수료 시 지원 불가)
-
-# Title : Corab Pro+지원 내용
-
-지원 대상: 카카오테크 부트캠프 인공지능 과정 교육생. 지원 내용: 구글 Colab Pro+ (5개월 분). 지원 방법: 개인 카드 결제 → 익월 환급 신청 → 익월 환급 완료. 내부 회계 절차에 따라 환급 신청 및 완료까지 시일이 소요됩니다.
-
-결제 시기: 8월 이내. 청구 시기: 9월 1~2주차. 환급 시기: 10월 10일 전후. 결제 및 청구 방 법은 각 시기별로 아래 페이지를 그대로 따라해주세요! Colab Pro+ 결제 및 청구 방법. 정 해진 결제 시기/방법, 청구 시기/방법을 지키지 않을 경우 환급이 불가합니다.
-
-개인 카드로 결제하신 Colab Pro+는 구독 취소를 하지 않을 경우 계속 구독료가 결제됩니 다. 지원이 끝나는 다음달부터는 자동 결제가 되지 않도록 개별적으로 구독 취소를 해주시 기 바랍니다. (24년 12월 결제 후 구독 취소). Colab Pro+가 아닌 다른 요금제 결제 시 환 급이 불가합니다. 중복 결제 및 오결제로 인한 책임은 교육생 본인에게 있습니다. 개인적으 로 이미 이용하고 있던 Colab 결제 내역에 대한 청구는 불가합니다. 달러와 원화가 기재된 카드 매출전표 외 다른 서류 제출 시 환급이 불가합니다. 정해진 결제 시기/방법, 청구 시기 /방법을 지키지 않을 경우 환급이 불가합니다. 개인 불찰로 지원기간 이후에 결제된 구독료 에 대한 책임은 교육생 본인에게 있습니다. Colab Pro+ 외 다른 서비스의 지원은 불가합니 다.
-
-# Title : (풀스택, 클라우드) AWS 사용료 지원 안내
-
-카카오테크 부트캠프에서는 풀스택, 클라우드 과정 교육생 대상 AWS 사용료를 지원해드립 니다. 인공지능(생성형 AI) 과정 교육생은 AWS 사용료 지원이 불가능 합니다. 지원 기간: 2024.07.01 ~ 2024.08.31. (2개월). 지원 내용: 지원 기간 내 최대 10만원. 사용 방식: 개인 계정을 생성하여 사용. 환급 방식: 지원 기간 종료 후 일괄 지급.
-
-# Title : 팀빌딩 방법
-
-팀빌딩 관련 내용은 디스코드 공지를 확인 부탁드립니다.
-
-# Title : 링크 안내
-
-디스코드 링크
-
-https://discord.gg/gGW8JJ4e
-
-통합신청센터 링크
-
-https://forms.gle/egsfisGU4uHeGdM17
-
-zoom강의실 링크
-
-https://zoom.us/j/94030410356?pwd=eHVMSFZyNDEyS01SWXkzSVVsN1NSZz09(비밀번호 12 34)
-
-구름 EXP 링크
-
-https://exp.goorm.io/education/TESIiAqKYZ88RcfzuJ/dashboard#/
-
-카카오테크 부트캠프 ZEP 링크
-
-https://zep.us/play/8lj15q(비밀번호 9999) 카카오테크 부트캠프 홈페이지
-
-https://kakao-tech-bootcamp.goorm.io/
-
-카카오테크 노션 링크
-
-https://goormkdx.notion.site/kakao-tech-bootcamp-0710eb08b5a743bea83e1871c5ae7465
-
-동아리 지원 안내
-
-• 목적:교육과휴식을균형있게운영하기위해자유로운동아리활동을지원. 동아리 안내 사항
-
-• 구성:최소인원10명이상
-• 중도포기자:발생시비용지급없음
-• 제한활동:종교활동,정치적특색활동제한
-
-동아리 비용 청구 방법
-• 제출방법:활동계획서,활동사진및일지구글폼제출(10월부터안내예정) • 지원금액:인당1만원,10명구성시총10만원지급
-• 지급방식:대표자계좌를통한지급(대표자정보필요)
-
-동아리 활동 지원 방법
-
-1. 활동 계획서 작성 및 팀 목록에 등록
-2. 정기 모임 시 사진 첨부 및 활동 일지 작성
-
-o 주1회이상활동필수
-
-o 활동일지에사진필수포함,양식자유
-
-[동아리 참가 팀 목록]
-
-• 팀이름:독서모임
-• 팀장: ella.lee(이지은)
-• 팀원: tami.kim(김현), harold.kim(김인서) 외 7명
-
-동아리 활동 계획서 작성 가이드
-
-• 팀 명단: 과정명/영문명(한글명), 팀장 및 팀원 정보
-• 공동목표:팀의목표작성(예:딥러닝CNN기초다지기) • 개인목표:팀원각각의개인목표작성
-• 운영방식:주차별,월별활동계획및달성목표설정
-
-# Title : K-digital Training 해커톤 대회 안내(KDT해커톤)
-
-• 대회명: K-digital Training 해커톤 (KDT 해커톤)
-• 신청기간: 8월 19일(월) - 9월 6일(금) • 공모주제:
-
-1. 저출산/고령사회에 필요한 첨단/디지털 서비스 개발
-2. 첨단/디지털 기술을 활용한 서비스 개발
-
-• 참가대상: KDT 훈련생 또는 수료생으로 구성된 팀(3-6인) • 시상내역:
-
-o 대상: 국무총리상 (상금 1,000만원)
-o 최우수상: 고용노동부 장관상 (상금 500만원) o 우수상: 고용노동부 장관상 (상금 300만원)
-o 장려상: 고용노동부 장관상 (상금 100만원)
-
-• 홈페이지: K-digital 해커톤 홈페이지
-참고: 이 해커톤 대회는 KDT 훈련생 및 수료생만을 위한 대회로, 팀을 자유롭게 구성하여 신청 가능합니다.
-
-# Title : 디스코드 퀴즈봇 탄생 안내
-
-• 소개: 교육 몰입도를 높이고 복습을 촉진하기 위해 디스코드 퀴즈봇을 도입했습니 다.
-• 퀴즈시작시간:매일오후2시부터시작
-• 참여 방법:
-
-o 각 과정별 quiz_bot채널에 입장 후 퀴즈 시작을 눌러 도전을 시작 o 처음시도에정답을맞춘경우에만EXP일일퀘스트완료
-o 문제는여러번풀수있지만,당일이후에는보상이적용되지않음
-
-• 일일 퀴즈:
-o 매일14시에 퀴즈봇이 다양한 문제 출제
-
-# Title : 전문 서적 지원 안내
-카카오테크 부트캠프에서는 과정과 관련된 전문 서적을 지원합니다.
-
-`*단, 교육 과정 특성에 따라 지원 서적 종류 및 규모에 일부 차이가 있습니다.*`
-
-### 풀스택 과정
-
----
-
-- (카카오 교재) 카카오클라우드와 MSA 개발 가정
-- (카카오 교재) Kakao cloud Kubernetes 기반 DevOps 구축과 CI/CD를 통한 App 배포 자동화
-- (카카오 교재) Kubernetes 기반 카카오클라우드 활용
-- (카카오 교재) 실무엔지니어를 위한 카카오 클라우드 활용
-- [리팩터링](https://product.kyobobook.co.kr/detail/S000001810241)
-- [Clean Code(클린 코드)](https://product.kyobobook.co.kr/detail/S000001032980)
-- [우아한 타입스크립트 with 리액트](https://product.kyobobook.co.kr/detail/S000210716282)
-- [UX/UI 디자이너를 위한 실무 피그마](https://product.kyobobook.co.kr/detail/S000200126715)
-- [클라우드 전환 그 실제 이야기](https://product.kyobobook.co.kr/detail/S000001804911)
-
-### 인공지능 과정
-
----
-
-- [LLM을 활용한 실전 AI 애플리케이션 개발](https://product.kyobobook.co.kr/detail/S000213834592)
-- [랭체인으로 LLM 기반의 AI 서비스 개발하기](https://product.kyobobook.co.kr/detail/S000212568407)
-- [파이썬 라이브러리를 활용한 데이터 분석 3판](https://product.kyobobook.co.kr/detail/S000201558138)
-- [파이썬을 이용한 머신러닝,딥러닝 실전개발](https://product.kyobobook.co.kr/detail/S000001766404)
-- [챗GPT와 랭체인을 활용한 LLM 기반 AI 앱 개발](https://product.kyobobook.co.kr/detail/S000213393997)
-- [도커,컨테이너 빌드업](https://product.kyobobook.co.kr/detail/S000001952232)
-- [쿠버네티스 교과서](https://product.kyobobook.co.kr/detail/S000208711643)
-- [케라스 창시자에게 배우는 딥러닝(개정 2판)](https://product.kyobobook.co.kr/detail/S000061584677)
-- [파이토치 트랜서포머를 활용한 자연어 처리와 컴퓨터비전 심층학습](https://product.kyobobook.co.kr/detail/S000209621433)
-
-### 클라우드 과정
-
----
-
-- (카카오 교재) 카카오클라우드와 MSA 개발 가정
-- (카카오 교재) Kakao cloud Kubernetes 기반 DevOps 구축과 CI/CD를 통한 App 배포 자동화
-- (카카오 교재) Kubernetes 기반 카카오클라우드 활용
-- (카카오 교재) 실무엔지니어를 위한 카카오 I 클라우드 활용
-- [레벨업 리액트 프로그래밍 with Next.js](https://product.kyobobook.co.kr/detail/S000213362009)
-- [MariaDB로 배우는 따라 하며 배우는 SQL 프로그래밍](https://product.kyobobook.co.kr/detail/S000200615696)
-- [이것이 우분투 리눅스다(개정판)](https://product.kyobobook.co.kr/detail/S000001810322)
-- [한 권으로 배우는 도커 & 쿠버네티스](https://product.kyobobook.co.kr/detail/S000213057687)
-- [러닝 깃허브 액션](https://product.kyobobook.co.kr/detail/S000213330264)
-- [LLM을 활용한 실전 AI 애플리케이션 개발](https://product.kyobobook.co.kr/detail/S000213834592)
-- [명품 JAVA Programming [개정 5판]](https://product.kyobobook.co.kr/detail/S000213799861)
-- [클라우드 네이티브 스프링 인 액션](https://product.kyobobook.co.kr/detail/S000212731527)
-
-### 유의사항
-
----
-
-1. 전문 서적은 구글폼을 통해 주소를 취합한 뒤 택배로 발송됩니다.
-    1. `참고` 구글폼 전원 제출 이후 발송 예정 
-2. 지원 서적은 보유 여부와 관계 없이 동일하게 지원되며 다른 서적을 선택하거나 변경할 수 없습니다.
-3. 해당 서적들은 교육 과정과 관련된 참고 자료 서적으로 이용해 주시기 바랍니다.
-
-# Title : 카테부 워크스페이스 교육장 모니터 AS 관련 안내
-
-안녕하세요! 카테부 교육생 여러분,
-워크스페이스에서 사용 중인 모니터 불량 문의가 증가하여 관련 안내 드립니다.
-
-**이상 있는 모니터 화면에 포스트잇을 붙이고 스레드에 사진을 업로드 해주세요.**
-
-포스트잇에는 증상을 상세하게 작성하여 화면 가운데에 부착해 주시기 바랍니다.
-포스트잇은 정수기 위에 비치되어 있으며, 이번 주 금요일까지 이상이 있는 모니터에 부착 후 사진을 올려주세요.
-
-**9월 20일(금) 오후 4시에 LG 수리 업체가 방문 예정입니다.**
-
-해당일 전까지 주변 모니터 자리를 사용 부탁드립니다.
-
-# Title : 팀 미션 발표회 안내 (9/12)
-
-안녕하세요! 카테부 교육생 여러분,
-팀 미션 발표회를 위해 준비하신 발표 자료와 보고서를 토대로 발표회가 진행됩니다.
-
-- 발표 자료는 제출하신 파일로 진행됩니다. (15분 발표 + 5분 질의응답)
-- 보고서 내용을 바탕으로 자유롭게 발표를 준비해 주시면 됩니다.
-- 발표자분들은 10시까지 타운홀에 모여주시기 바랍니다. 발표 자료 및 장비 테스트가 진행될 예정입니다.
-- 이번 발표회는 1등을 가리는 자리가 아니라, 피드백을 통해 프로젝트에 도움을 드릴 수 있는 자리입니다.
-
-[카카오테크 부트캠프 팀 미션 발표회 타임테이블 & 발표 순서](https://docs.google.com/spreadsheets/d/1doxPZF5s-t6joagl-PnQl_dpb7GOrZHJstWkPqy3450/edit?gid=0#gid=0)
-
-# Title : 네트워킹 및 교육 일정 안내
-
-네트워킹 및 향후 일정에 대해 안내드립니다.
-
-**[네트워킹 일정]**
-
-- 9월 20일(금)
-- 10월 18일(금)
-- 11월 22일(금)
-
-**[휴강 일정]**
-
-- 9월 9일(월)
-- 10월 4일(금) ~ 10월 11일(금)
-- 12월 23일(월) ~ 12월 25일(수)
-
-**[주말 수업 일정]**
-
-- 9월 7일(토)
-- 9월 28일(토)
-- 10월 26일(토)
-- 11월 2일(토)
-- 11월 9일(토)
-- 11월 16일(토)
-- 11월 30일(토)
-- 12월 7일(토)
-- 12월 14일(토)
-
-# Title : 입실/퇴실 ZOOM 스크린샷 촬영 출결 안내
-
-안녕하세요! 카테부 교육생 여러분,
-입/퇴실 출결 관리를 위해 ZOOM 스크린샷 촬영을 진행할 예정입니다.
-
-지각/조퇴/외출 시에는 QR 체크를 부탁드리며, 스크린샷 촬영 시간에도 참여 부탁드립니다.
-
-- **스크린샷 촬영 시 눈코입과 이름을 설정해 주세요.**
-- **뒷배경은 흐리게 설정 불가하며, 원본 그대로 보여주셔야 합니다.**
-- **HRD-Net 앱 출결은 8시 50분 ~ 9시 10분, 17시 50분 ~ 18시 10분에 진행됩니다.**
-
-스크린샷 촬영은 퍼실리테이터가 도와드릴 예정입니다.
-
-# Title : 카테부 교육장 도서관 OPEN 안내
-
-카테부 교육장 도서관이 오픈되었습니다.
-
-- 서적은 외부로 가져갈 수 없으며, 교육장 내에서만 읽어주시기 바랍니다.
-- 서적 대여는 명부 리스트에 작성 후 대여 가능합니다. (추후 대여 방식에 대해 자세히 안내 예정)
-
-매달 IT 관련 서적이 기증될 예정이니 많은 관심 부탁드립니다.
Index: document_retriever.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain_core.documents import Document\nfrom langchain_text_splitters import MarkdownHeaderTextSplitter\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.prompts.few_shot import FewShotPromptTemplate\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain_community.retrievers import BM25Retriever\nfrom langchain.retrievers import EnsembleRetriever\nfrom langchain.retrievers.multi_query import MultiQueryRetriever\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom conversation_history import history\nfrom mongo_client import get_mongo_client\n\nimport pprint\nimport json\nimport logging, os\nimport ssl\nfrom dotenv import load_dotenv\n\ndef load_md_files(file_path): # file path 내의 모든 md 파일을 읽어 문서 데이터를 가져온다. \n    # 해당 폴더 내의 모든 .md 파일을 가져오기\n    loader = TextLoader(file_path)\n    documents = loader.load()  \n    print(f\"Loaded {len(documents)} documents from the MD.\")\n    print(\"len(docs):\", len(documents) )\n\n    return documents\n\ndef split_docs(documents):\n\n    # 단계 1: 문서 로드(Load Documents)\n    assert len(documents) == 1 # 수정 - 파일 여러 개일 떄 \n    assert isinstance(documents[0], Document) # 수정 - 파일 여러 개일 때 \n    readme_content = documents[0].page_content \n\n    \"\"\"# 단계 2: 문서 분할(Split Documents)\"\"\"\n    headers_to_split_on = [\n        (\"#\", \"Header 1\"),\n        (\"##\", \"Header 2\"),\n        (\"###\", \"Header 3\"),\n    ]\n\n    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)\n    splitted_md = markdown_splitter.split_text(readme_content)\n    return splitted_md\n\ndef create_bm25_retriever(splitted_docs): # vectorDB 생성\n    bm25_retriever = BM25Retriever.from_documents(\n        splitted_docs,\n        )\n    bm25_retriever.k = 1  # BM25Retriever의 검색 결과 개수를 1로 설정합니다.\n    print(\"bm25 retriever created\")\n    return bm25_retriever\n\ndef create_FAISS_retriever(splitted_docs): # vectorDB 생성\n    embedding_function = OpenAIEmbeddings()\n    faiss_db = None\n    faiss_index_path = \"data/retrievers/faiss_index\"  # FAISS 인덱스를 저장할 디렉토리 경로\n    index_faiss_file, index_pkl_file = os.path.join(faiss_index_path, \"index.faiss\"), os.path.join(faiss_index_path, \"index.pkl\")\n\n    if os.path.exists(index_faiss_file) and os.path.exists(index_pkl_file):  # Check if both files exist\n        print(\"이미 FAISS index 존재\")\n        faiss_db = FAISS.load_local(\n            faiss_index_path,\n            embeddings=embedding_function,\n            allow_dangerous_deserialization=True  # 역직렬화 혀용 \n        )\n    else:\n        print(\"새롭게 FAISS index 만들기\")\n        # 새로운 문서 리스트를 생성하거나 불러와서 FAISS 벡터스토어를 초기화\n        faiss_db = FAISS.from_documents(splitted_docs, embedding=embedding_function)\n        faiss_db.save_local(faiss_index_path) # FAISS 인덱스를 로컬에 저장\n\n    # results = faiss_db.similarity_search_with_score(query, top_k = 3)\n    # # for 문을 사용하여 결과 출력\n    # for idx, (document, score) in enumerate(results):\n    #     print(f\"Result {idx + 1}:\")\n    #     #print(f\"Document: {document}\")\n    #     print(f\"Similarity Score: {score}\")\n    #     print(\"-\" * 50)  # 구분선 출력\n    faiss_retriever = faiss_db.as_retriever(search_kwargs={\"score_threshold\": 0.7})\n    # faiss_retriever.score\n    return faiss_retriever, faiss_db\n\ndef create_ensemble_retriever(retrievers): # retrievers: lst\n    ensemble_retriever = EnsembleRetriever(\n        retrievers= retrievers,\n        weights=[0.7, 0.3],\n    )\n    print(\"Retriever created.\")\n\n    return ensemble_retriever \n\n\ndef create_qa_chain(ensemble_retriever):\n    prompt = PromptTemplate.from_template(\n        \"\"\"You are an assistant for question-answering tasks. \n        Use the following pieces of retrieved context to answer the question. \n        Consider the intent behind the question to provide the most relevant and accurate response. \n        Remember to compare the specific time in the question with the time mentioned in the context to determine the correct answer.\n        If you don't know answer, just give me an answer based on your basic knowledge in detail.\n        #Question: \n        {question} \n        #Context: \n        {context} \n\n        #Answer:\"\"\"\n    )\n\n\n    llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.2, streaming=True) # , max_tokens = 150)\n    multiquery_retriever = MultiQueryRetriever.from_llm(  # \n        retriever=ensemble_retriever,\n        llm=llm,\n    )\n\n    print(\"LLM created.\")\n    \"\"\"Create a QA chain using the retriever.\"\"\"\n    rag_chain = (\n        {\"context\": multiquery_retriever, \"question\": RunnablePassthrough()}\n        | prompt\n        | llm\n        | StrOutputParser()\n    )\n    return rag_chain\n\ndef my_retriever(file_path):\n    ssl._create_default_https_context = ssl._create_unverified_context     \n    load_dotenv() # api key 정보 로드\n    \n    # RAG를 위한 vectorDB와 qa chain 을 로드함. \n    documents = load_md_files(file_path)\n    splitted_docs = split_docs(documents)\n    bm25_retriever = create_bm25_retriever(splitted_docs)\n    faiss_retriever, faiss_db = create_FAISS_retriever(splitted_docs)\n    ensemble_retriever = create_ensemble_retriever([bm25_retriever, faiss_retriever])\n    rag_chain = create_qa_chain(ensemble_retriever)\n    \n    return rag_chain, faiss_db\n\n \n# ==== test ======\n\"\"\"if __name__ == \"__main__\":\n    rag_chain = my_retriever('data/ktb_data_09.md')   \n    question = '8월에 며칠 이상 출석해야 훈련 장려금 받을 수 있어?'\n    print(\"question:\\n\", question)\n    response = rag_chain.invoke(question)\n    print('response:\\n', response)\n\"\"\"
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/document_retriever.py b/document_retriever.py
--- a/document_retriever.py	(revision 0a6116d258dbb8c406e2851953ea33c3cdd8e691)
+++ b/document_retriever.py	(date 1727341860995)
@@ -112,7 +112,7 @@
     )
 
 
-    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.2, streaming=True) # , max_tokens = 150)
+    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.2, streaming=True, max_tokens = 150)
     multiquery_retriever = MultiQueryRetriever.from_llm(  # 
         retriever=ensemble_retriever,
         llm=llm,
Index: Dockerfile
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># 베이스 이미지로 Python 3.12 slim 사용\nFROM python:3.12-slim\n\n# 작업 디렉토리 설정\nWORKDIR /app\n\n# 시스템 패키지 설치\n# 시스템 패키지 설치 (필수 라이브러리 추가)\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    gcc \\\n    build-essential \\\n    libc-dev \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Python 의존성 설치를 위한 requirements.txt 복사\nCOPY requirements.txt .\n\n# Python 패키지 설치\nRUN pip install --no-cache-dir -r requirements.txt\n\n# 애플리케이션 코드 및 PDF 데이터 복사\nCOPY . .\n\n# Flask 환경 변수 설정\nENV FLASK_APP=app.py\nENV FLASK_RUN_HOST=0.0.0.0\nENV FLASK_RUN_PORT=5001\n\n# 5001 포트를 컨테이너 외부에 노출\nEXPOSE 5001\n\n# 애플리케이션 실행\nCMD [\"flask\", \"run\", \"--host=0.0.0.0\", \"--port=5001\"]\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Dockerfile b/Dockerfile
--- a/Dockerfile	(revision 0a6116d258dbb8c406e2851953ea33c3cdd8e691)
+++ b/Dockerfile	(date 1726707409632)
@@ -23,9 +23,12 @@
 
 # Flask 환경 변수 설정
 ENV FLASK_APP=app.py
+ENV FLASK_ENV=development
+ENV FLASK_DEBUG = 1
 ENV FLASK_RUN_HOST=0.0.0.0
 ENV FLASK_RUN_PORT=5001
 
+
 # 5001 포트를 컨테이너 외부에 노출
 EXPOSE 5001
 
Index: etc/error_handler_test/chatgpt_api.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import openai\nimport json\nimport logging\nimport warnings\nimport os\nfrom flask import Flask, request, jsonify, Response, abort\nfrom dotenv import load_dotenv\nfrom openai import OpenAIError\n\n\n# 로깅 설정\nlogging.basicConfig(\n    filename='./logging/error_log.log',\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    datefmt='%Y-%m-%d %H:%M:%S'\n)\n\n\nload_dotenv() # # .env 파일에서 환경 변수를 로드합니다\nOPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY2\") # API 키 설정\nMAX_TOKENS_OUTPUT = 600\nMODEL_VERSION = \"gpt-4o\" # \"gpt-3.5-turbo\"  \n\ndef stream_chatgpt(system_prompt, user_prompt):\n    client = openai.OpenAI(api_key=OPENAI_API_KEY)\n    try:\n        response = client.chat.completions.create(\n            model=MODEL_VERSION,\n            messages=[\n                {\"role\": \"system\", \"content\": system_prompt},\n                {\"role\": \"user\", \"content\": user_prompt}\n            ],\n            temperature=0.0, # 출력의 다양성 조절 (0~1), 높을 수록 창의적인 대답\n            max_tokens= MAX_TOKENS_OUTPUT, # 최대 출력 토큰 개수 \n            n = 1,         # 생성 답변 개수,\n            stream=True\n        )\n        def event_stream(): #stream generator\n            print(\"response\", response)\n            for chunk in response:\n                text = chunk.choices[0].delta.get('content')\n                if len(text):\n                    yield text\n                    print(text)\n        return Response(event_stream(), mimetype='text/event-stream')\n    except Exception as e:\n        print(f\"Error while calling chatGPT API function call: {str(e)}\")\n        logging.error(f\"Error while calling chatGPT API function call: {str(e)}\")\n        abort(500)\n        # return None\n    \n# 동기식 chatGPT 함수\ndef cls_chatgpt(system_prompt, user_prompt):\n    client = openai.OpenAI(api_key=OPENAI_API_KEY)\n    try:\n        response = client.chat.completions.create(\n            model=MODEL_VERSION,\n            messages=[\n                {\"role\": \"system\", \"content\": system_prompt},\n                {\"role\": \"user\", \"content\": user_prompt}\n            ],\n            temperature=0.0, # 출력의 다양성 조절 (0~1), 높을 수록 창의적인 대답\n            max_tokens= MAX_TOKENS_OUTPUT, # 최대 출력 토큰 개수 \n            n = 1,         # 생성 답변 개수,\n            stream=True\n        )\n        return response.choices[0].message.content\n    except Exception as e:\n        print(f\"Error while calling chatGPT API function call: {str(e)}\")\n        logging.error(f\"Error while calling chatGPT API function call: {str(e)}\")\n        raise e # OpenAIError\n    \n\n\"\"\"def test():\n    system_prompt = \"you are a helpful assistant \"\n    user_prompt = \"한국 전래 동화 3개만 알려줘\"\n    stream_chatgpt(system_prompt, user_prompt)\n\ntest()\n\"\"\"\n    \n\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/etc/error_handler_test/chatgpt_api.py b/etc/error_handler_test/chatgpt_api.py
--- a/etc/error_handler_test/chatgpt_api.py	(revision 0a6116d258dbb8c406e2851953ea33c3cdd8e691)
+++ b/etc/error_handler_test/chatgpt_api.py	(date 1724656227004)
@@ -45,9 +45,8 @@
                     print(text)
         return Response(event_stream(), mimetype='text/event-stream')
     except Exception as e:
-        print(f"Error while calling chatGPT API function call: {str(e)}")
         logging.error(f"Error while calling chatGPT API function call: {str(e)}")
-        abort(500)
+        raise e # OpenAIError
         # return None
     
 # 동기식 chatGPT 함수
@@ -67,7 +66,6 @@
         )
         return response.choices[0].message.content
     except Exception as e:
-        print(f"Error while calling chatGPT API function call: {str(e)}")
         logging.error(f"Error while calling chatGPT API function call: {str(e)}")
         raise e # OpenAIError
     
Index: utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import openai\nimport json\nimport logging\nfrom flask import request, Response\nfrom get_weather import get_weather_info\nfrom find_routes_v2 import get_route_description\nfrom conversation_history import save_conversation\nfrom openai import OpenAIError\nfrom werkzeug.exceptions import BadRequest\nfrom conversation_history import history\nimport time\nimport os\n\n# 환경 변수에서 API 키와 PDF 경로를 로드\nOPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\nTMAP_API_KEY = os.getenv('TMAP_API_KEY')\nKAKAO_MAP_API_KEY = os.getenv('KAKAO_MAP_API_KEY1')\nWEATHER_API_KEY = os.getenv('WEATHER_API_KEY')\nLOCATION1 = os.getenv('LOCATION1')\n\n# LLM 변수 정의\nSTREAM_TOKEN_SIZE = 1 # 스트림 토큰 단위 default 125\nMODEL_VERSION = \"gpt-4o-mini\" # \"gpt-3.5-turbo\"\nMAX_TOKENS_OUTPUT = 500\n\ndef stream_message(text):  # 데이터가 한 글자 단위로 스트리밍 된다.\n    for char in text:\n        yield f\"data: {char}\\n\\n\"\n\ndef stream_chatgpt(system_prompt, user_prompt, user_id, chat_id):\n    print(\"stream_chatgpt()\")\n    first = time.time()\n    print(f\"first: {first}\")\n    # 기존 N개 데이터 히스토리 가져오기\n    messages = [{\"role\": \"system\", \"content\": system_prompt + \"\\n 정보를 일반 텍스트로 작성해 주세요. 굵게 표시하지 말고, 특수 형식 없이 일반 텍스트로만 작성해 주세요.\"},\n                {\"role\": \"user\", \"content\": user_prompt} ]\n    if user_id is not None and chat_id is not None:\n        conv_history = history(user_id, chat_id, limit=2)\n        for conv in conv_history:\n            role = conv.get('role') # 'user' or 'system'\n            content = conv.get('text')\n            messages.append({\"role\": role, \"content\": content})\n\n    print('history:', messages)\n    client = openai.OpenAI(api_key=OPENAI_API_KEY)\n    second = time.time()\n    print(f\"second: {second}\")\n    try:\n        response = client.chat.completions.create(\n            model=MODEL_VERSION,\n            messages= messages,\n            temperature=0.0, # 출력의 다양성 조절 (0~1), 높을 수록 창의적인 대답\n            max_tokens= MAX_TOKENS_OUTPUT, # 최대 출력 토큰 개수\n            n = 1,         # 생성 답변 개수,\n            stream=True\n        )\n        def event_stream(): #stream generator\n            result_txt = ''\n            for chunk in response:\n                text = chunk.choices[0].delta.content\n                #print(\"chunk.choices[0]\", chunk.choices[0])\n                print(\"- text:\", text, \"\\n\")\n                if text:\n                    result_txt += text\n                    yield f\"data: {text}\\n\\n\"\n\n            print(\"답변 결과:\\n\", result_txt)\n            # 답변 결과 DB 에 저장\n            save_conversation(user_id, chat_id, \"system\", result_txt)\n        return Response(event_stream(), mimetype='text/event-stream')\n    except OpenAIError as e:\n        logging.error(f\"Error while calling chatGPT API function call: {str(e)}\")\n        raise e # OpenAIError\n    except Exception as e:\n        logging.error(f\"Error: {str(e)}\")\n        raise e # OpenAIError\n\ndef text_chatgpt(system_prompt, user_prompt): # text 형식으로 리턴\n    client = openai.OpenAI(api_key=OPENAI_API_KEY)\n    try:\n        response = client.chat.completions.create(\n            model=MODEL_VERSION,\n            messages=[\n                {\"role\": \"system\", \"content\": system_prompt + \"\\n 정보를 일반 텍스트로 작성해 주세요. 굵게 표시하지 말고, 특수 형식 없이 일반 텍스트로만 작성해 주세요.\"},\n                {\"role\": \"user\", \"content\": user_prompt}\n            ],\n            temperature=0.0, # 출력의 다양성 조절 (0~1), 높을 수록 창의적인 대답\n            max_tokens= MAX_TOKENS_OUTPUT, # 최대 출력 토큰 개수\n            n = 1,         # 생성 답변 개수,\n            stream=False\n        )\n        return response.choices[0].message.content\n    except OpenAIError as e:\n        logging.error(f\"Error while calling chatGPT API function call: {str(e)}\")\n        raise e # OpenAIError\n    except Exception as e:\n        logging.error(f\"Error: {str(e)}\")\n        raise e # OpenAIError\n\ndef topic_classification(user_input):\n    system_prompt = \"\"\"\n            You are a classifier. Your task is to analyze '{user_input}'.\n        - If '{user_input}' is a question about the asking weather, return 'WEATHER'.\n        - If '{user_input}' is a question about public transportation routes involving a specific origin and destination, return 'TRANS'.\n        - If '{user_input}' does not match either of the above cases, return 'ELSE'.\n        \"\"\"\n    return text_chatgpt(system_prompt, user_input)\n\ndef extract_arrv_dest(user_input): #user input 에서 출발지와 도착지 출력\n    system_prompt = \"\"\"\n            Your task is to identify the departure and destination from the user's input.\n            Follow these guidelines:\n            1. If either the departure or destination is ambiguous or unclear, mark it as unknown.\n            2. If the input refers to the user's current location, mark it as current.\n            3. If the input suggests the user's home location, mark it as home.\n            4. Please return a dictionary formatted like this : {\"from\":departure, \"to\":destination}\n            \"\"\"\n    return text_chatgpt(system_prompt =system_prompt, user_prompt= user_input )\n\ndef handle_weather_topic(user_input, user_id, chat_id):\n    weather_info = get_weather_info()\n    system_prompt = (f\"You are a helpful assistant, and you will kindly answer questions about current weather. \"\n              f\"한국어로 대답해야해. 현재 날씨 정보는 다음과 같아. {weather_info}, \"\n              \"이 날씨 정보를 다 출력할 필요는 없고, 주어진 질문인 '{user_input}'에 필요한 답만 해줘 \")\n    result = stream_chatgpt(system_prompt, user_input, user_id, chat_id)\n    return result\n\ndef handle_trans_topic(user_input, user_id, chat_id):\n    dict_string = extract_arrv_dest(user_input)\n    from_to_dict = json.loads(dict_string)\n    result_txt = get_route_description(from_to_dict, TMAP_API_KEY, KAKAO_MAP_API_KEY)\n    system_prompt = f\"너는 출발지에서 목적지까지 경로를 안내하는 역할이고, 한국어로 대답해야해.\"\\\n              f\"사용자는 경로에 대해 요약된 텍스트를 줄거야. 너는 그걸 자연스럽게 만들어주면 돼. \"\\\n              f\"출발지는 ```{from_to_dict['from']}```이고 목적지는 ```{from_to_dict['to']}```임.  \"\n    user_prompt = f\"다음을 자연스럽게 다시 말해줘:\\n```{result_txt}``` \"\n    return stream_chatgpt(system_prompt, user_prompt, user_id, chat_id)\n\ndef handle_else_topic(user_input, user_id, chat_id):\n    system_prompt = (\"You are a helpful assistant.\"\n              \"사용자들은 한국어로 질문할 거고, 너도 한국어로 대답해야돼\")\n    result = stream_chatgpt(system_prompt, user_input, user_id, chat_id)\n    return result\n\ndef get_request_data(title=None):\n    params = request.get_json()\n    print(\"params:\", params)\n    if not params:  # JSON 데이터가 없는 경우\n        raise BadRequest(\"No request body\")\n    # 변수가 3개 : content, user_id, chat_id\n    if 'content' not in params or not isinstance(params['content'], str) or not params['content'].strip() :  # 'content' 필드가 없거나 값이 비어 있는 경우\n        raise BadRequest(\"No content field in request body, empty value or invalid value\")\n    if title is None: # title은 user_id, chat_id 가 필요 없음\n        if 'user_id' not in params or not params['user_id'] or not isinstance(params['user_id'], int):\n            raise BadRequest(\"No user_id field in request body, empty value or invalid value\")\n        if 'chat_id' not in params or not params['chat_id'] or not isinstance(params['chat_id'], int):\n            raise BadRequest(\"No chat_id field in request body, empty value or invalid value\")\n\n    #content, user_id, chat_id = params['content'], params['user_id'], params['chat_id']\n    #return content, user_id, chat_id\n    return params
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/utils.py b/utils.py
--- a/utils.py	(revision 0a6116d258dbb8c406e2851953ea33c3cdd8e691)
+++ b/utils.py	(date 1727163577371)
@@ -25,8 +25,9 @@
 
 def stream_message(text):  # 데이터가 한 글자 단위로 스트리밍 된다.
     for char in text:
-        yield f"data: {char}\n\n"
+        yield f"data: {char}\n\n" 
 
+
 def stream_chatgpt(system_prompt, user_prompt, user_id, chat_id):
     print("stream_chatgpt()")
     first = time.time()
Index: test/input/user_inputs.json
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>{\n  \"user_inputs\": [\n    \"카카오 클라우드 교육 채널에 로그인이 되지 않을 경우 어떻게 해야 하나요?\",\n    \"카카오 클라우드 교육의 전체 일정과 내용은 어떻게 구성되어 있나요?\",\n    \"카카오 클라우드 교육의 시간과 장소는 어떻게 되나요?\",\n    \"카카오 클라우드 교육의 방식은 어떻게 어떻게 되나요?\",\n\n    \"카카오 부트캠프 가는 길 알려줘\",\n    \"카카오 부트캠프 교육장 주소는 어떻게 되나요?\",\n    \"카카오 부트캠프 교육장 주차 지원이 되나요?\",\n    \"카카오 부트캠프 가는 길 알려줘\",\n\n    \"ChatGPT Plus 구독료 지원 방법 안내해줘\",\n    \"ChatGPT Plus 구독료 지원을 신청하는 방법은 무엇인가요?\",\n    \"ChatGPT Plus 구독료 지원 대상과 횟수에 대해서 안내해줘\",\n    \"ChatGPT Plus 구독료 청구 방법에 대해서 알려줘\",\n    \"chatgpt plus 구독료 청구할 때, 증빙자료에 뭐 들어가야해?\",\n    \"chatgpt plus 구독료 청구할 때, 유의 사항에 대해서 알려줘\"\n\n\n  ]\n}\n\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/test/input/user_inputs.json b/test/input/user_inputs.json
--- a/test/input/user_inputs.json	(revision 0a6116d258dbb8c406e2851953ea33c3cdd8e691)
+++ b/test/input/user_inputs.json	(date 1724828542777)
@@ -16,8 +16,6 @@
     "ChatGPT Plus 구독료 청구 방법에 대해서 알려줘",
     "chatgpt plus 구독료 청구할 때, 증빙자료에 뭐 들어가야해?",
     "chatgpt plus 구독료 청구할 때, 유의 사항에 대해서 알려줘"
-
-
   ]
 }
 
