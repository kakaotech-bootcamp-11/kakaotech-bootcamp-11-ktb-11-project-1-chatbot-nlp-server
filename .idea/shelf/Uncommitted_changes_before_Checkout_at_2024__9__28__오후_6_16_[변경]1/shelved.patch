Index: test.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/test.py b/test.py
new file mode 100644
--- /dev/null	
+++ b/test.py	
@@ -0,0 +1,79 @@
+import unittest
+import json
+import os
+from datetime import datetime
+from app import app
+
+class AppIntegrationTestCase(unittest.TestCase):
+    def setUp(self):
+        self.app = app.test_client()
+        self.app.testing = True
+        # JSON 파일 경로 설정 
+        self.user_input_file = 'test/input/user_inputs.json'
+        # 출력 파일을 저장할 디렉토리 설정
+        self.output_dir = 'test/output'
+
+        # 디렉토리가 없으면 생성
+        if not os.path.exists(self.output_dir):
+            os.makedirs(self.output_dir)
+
+    def test_full_functionality(self):
+        """app.py의 모든 기능을 한 번에 테스트 (자동 분류)"""
+        # JSON 파일 읽기
+        with open(self.user_input_file, 'r', encoding='utf-8') as json_file:
+            data = json.load(json_file)
+            user_inputs = data.get('user_inputs', [])
+
+        results = []
+
+        for user_input in user_inputs:
+            # 모든 사용자 입력을 단일 엔드포인트로 보냅니다
+            response = self.app.post('/conv', 
+                                     data=json.dumps({'content': user_input}),
+                                     content_type='application/json')
+
+            result = {
+                'input': user_input,
+                'status_code': response.status_code,
+                'response_text': response.get_data(as_text=True)
+            }
+            results.append(result)
+
+            # 상태 코드가 200인지 확인
+            self.assertEqual(response.status_code, 200)
+            # 응답 내용이 비어있지 않은지 확인
+            self.assertTrue(len(result['response_text']) > 0)
+
+        # 현재 시간 기준으로 파일명 생성
+        current_time = datetime.now().strftime('%Y%m%d_%H%M%S')
+        output_file = os.path.join(self.output_dir, f'test_results_{current_time}.json')
+
+        # 결과를 JSON 파일로 저장
+        with open(output_file, 'w', encoding='utf-8') as json_file:
+            json.dump(results, json_file, ensure_ascii=False, indent=2)
+
+if __name__ == '__main__':
+    unittest.main()
+
+"""user_inputs = [
+            "교육 중간에 탈락하면 페널티가 있어?", 
+            "훈련 장려금은 얼마야?",
+            "출석 확인은 어떻게 해?", 
+            "카카오 클라우드 교육 채널에 어떻게 로그인해?", 
+            "인프런 강의 지원은 어떻게 받을 수 있어?", 
+            "사원증은 언제 배부돼?", 
+            "8월 교육 일정은 어떻게 돼?", 
+            "팀 미션 세부 내용은 뭐야?", 
+            "ChatGPT Plus 지원 방법은 어떻게 돼?", 
+            "교육 중도 포기 시 불이익이 있어?", 
+            "출석 인정 기준은 무엇이야?", 
+            "출석 입력요청대장은 어떻게 작성해?", 
+            "Colab Pro+ 지원 내용은 뭐야?", 
+            "카카오테크 부트캠프 가는 길은?", 
+            "클라우드 강의 일정은 어떻게 돼?", 
+            "포기 사유가 취업일 경우 어떻게 해야 해?", 
+            "예비군 훈련 시 출석 인정 서류는 무엇이야?", 
+            "중도포기서 제출 방법은?", 
+            "방학과 토요일 수업 안내는 어떻게 돼?", 
+            "교육 중도 포기 시 국민내일배움카드 사용에 불이익이 있어?"
+        ]"""""
\ No newline at end of file
Index: evaluation/RAG_eval.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/evaluation/RAG_eval.py b/evaluation/RAG_eval.py
new file mode 100644
--- /dev/null	
+++ b/evaluation/RAG_eval.py	
@@ -0,0 +1,102 @@
+### pdf title 단위로 데이터 생성하기 
+import os 
+from dotenv import load_dotenv
+from langchain.chains import RetrievalQA
+from langchain.chat_models import ChatOpenAI
+from langchain.evaluation.qa import QAGenerateChain
+from langchain.evaluation.qa import QAEvalChain
+from langchain_text_splitters import RecursiveCharacterTextSplitter, SpacyTextSplitter
+from langchain.prompts import PromptTemplate
+from langchain.chains import LLMChain
+
+
+from pdf_retriever import *
+
+
+load_dotenv() # # .env 파일에서 환경 변수를 로드합니다
+OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY") # API 키 설정
+# LLM 변수 정의 
+MAX_TOKENS_OUTPUT = 200
+STREAM_TOKEN_SIZE = 30
+MODEL_VERSION = "gpt-4o" # "gpt-3.5-turbo"  
+
+
+"""def split_docs(documents):
+    # 문서를 처리하기 좋은 크기의 조각으로 나누는 스플리터를 설정합니다.
+    # 'ko_core_news_sm'은 한국어 처리를 위한 Spacy 모델입니다.
+    text_splitter = RecursiveCharacterTextSplitter(
+        # 청크 크기를 매우 작게 설정합니다. 예시를 위한 설정입니다.
+        chunk_size=250,
+        # 청크 간의 중복되는 문자 수를 설정합니다.
+        chunk_overlap=30,
+        # 문자열 길이를 계산하는 함수를 지정합니다.
+        length_function=len,
+        # 구분자로 정규식을 사용할지 여부를 설정합니다.
+        is_separator_regex=False
+    )
+
+    splitted_documents = text_splitter.split_documents(documents)  # 문서를 나눕니다.
+    print(f"Split into {len(splitted_documents)} document chunks.")
+    return splitted_documents"""
+
+
+
+
+def paragraphWiseDocumentReading(pdf_path):
+    documents = load_pdf(pdf_path)
+    splitted_documents = split_docs(documents, SpacyTextSplitter)
+    """for doc in splitted_documents[:50]:
+        print(doc)
+        print("-------")"""
+
+
+
+def create_QA_examples(splitted_documents): # 문서에 대해서 질문과 모범답안 생성해주는 함수 
+    llm = ChatOpenAI(model=MODEL_VERSION)
+    #prompt = PromptTemplate(
+    #    input_variables=["doc"],
+    #    template = "한국어로 질문과 텍스트를 만들어줘: {doc}"
+    #)
+   # LLMChain 생성
+    #llm_chain = LLMChain(llm=llm, prompt=prompt)
+    
+    # QAGenerateChain 생성 (llm_chain을 인자로 전달)
+    QA_generation_chain = QAGenerateChain.from_llm(llm)  # QA 체인 생성 
+
+    splitted_documents = [t.page_content if hasattr(t, 'page_content') else str(t) for t in splitted_documents]
+    #QA_examples = QA_generation_chain.apply_and_parse(
+    QA_examples = QA_generation_chain.apply(
+        [{"doc": t} for t in splitted_documents]
+    )
+    QA_examples = [item['qa_pairs'] for item in QA_examples]
+    print("QA_examples:\n", QA_examples)
+    
+    return QA_examples
+        
+
+def QA_evaluation(retrieval_qa, QA_examples):
+    llm = ChatOpenAI(temperature = 0.0, model=MODEL_VERSION)
+    predictions = retrieval_qa.apply(QA_examples) # 예측값 생성
+    eval_chain = QAEvalChain.from_llm(llm = llm) # 평가 chain 생성
+
+    graded_outputs = eval_chain.evaluate(QA_examples, predictions)
+    num_correct = 0
+    for i, qa_pair in enumerate(QA_examples):
+        print(f"Example {i}:")
+        print("Question: " + predictions[i]['query'])
+        print("Real Answer: " + predictions[i]['answer'])
+        print("Predicted Answer: " + predictions[i]['result'])
+        print("Predicted Grade: " + graded_outputs[i]['results'])
+        print("-"*10)
+        if graded_outputs[i]['results'] == "CORRECT":
+            num_correct += 1
+    print('accuracy:', num_correct/len(QA_examples)*100)
+
+if __name__ == "__main__":
+    pdf_path = './data/ktb_data_07_3.pdf'
+    retrieval_qa = pdf_retriever(pdf_path, MODEL_VERSION, OPENAI_API_KEY)
+    
+    documents = load_pdf(pdf_path)
+    splitted_documents = split_docs(documents, SpacyTextSplitter) 
+    QA_examples = create_QA_examples(splitted_documents[:10])
+    QA_evaluation(retrieval_qa, QA_examples)
Index: find_routes_v2.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/find_routes_v2.py b/find_routes_v2.py
new file mode 100644
--- /dev/null	
+++ b/find_routes_v2.py	
@@ -0,0 +1,163 @@
+import json
+import os 
+import requests
+import logging
+from urllib.parse import quote
+
+
+# 로깅 설정
+logging.basicConfig(
+    filename='error_log.log',
+    level=logging.ERROR,
+    format='%(asctime)s - %(levelname)s - %(message)s',
+    datefmt='%Y-%m-%d %H:%M:%S'
+)
+
+def TMAP_API(start_lat, start_lon, end_lat, end_lon, TMAP_API_KEY):
+    url = "https://apis.openapi.sk.com/transit/routes"
+    # 헤더 정의
+    headers = {
+        "Content-Type": "application/json", # "application/xml": xml 형식으로 request 하고 싶으면 
+        "appKey": TMAP_API_KEY # sk openapi 웹페이지에서 만든 API KEY, .env에 지정해놓음
+    }
+    params = {
+        "startX": start_lon,
+        "startY": start_lat,
+        "endX": end_lon,
+        "endY": end_lat,
+        "count": 1, # 답변 출력 개수 1~10, 기본값은 10이다. 
+        "lang": 0, # 출력 언어 선택 - 0: 한국어, 1: 영어
+        "format": "json" # 출력 포맷 "json" or "xml"
+    }
+    
+    # API 호출 
+    response = requests.post(url, json=params, headers=headers) # POST 명령어 사용 
+    json = response.json()
+    if 'result' in json.keys():
+        error_code, error_message = json['result']['status'], json['result']['message']
+        logging.error(f"TMAP_API 에러 - 에러 코드: {error_code}, 에러 메시지 :{error_message}")
+        return error_message
+    return response.json()
+        
+        
+    """ # 경로 정보 추출
+        # json = response.json()
+        return response.json()
+    except Exception as e:
+        return {'error': f'Tmap Public trans API do not respond\nerror msg:{response.json()}'}
+"""
+
+def get_coord(place_name, KAKAO_MAP_API_KEY): # place 이름을 주면 위도 경도 좌표를 포함한 dict을 리턴 
+  x,y=  37.3948, 127.1112 # 장소 검색 기준 좌표 - 판교역
+  radius = 100 # 기준 좌표에서 몇 KM 반경으로 검색할 것인가? 
+  format = "json"
+  size = 1 #검색 결과 사이즈 
+  sort = 'accuracy'
+  print("place:", place_name)
+  # KAKAO_API_KEY = "KakaoAK 4f55134dcdd4c80401cb0f0d73403f35" # 'KaKaoAK xxxxx' 형태 
+  # KAKAO_MAP_API_KEY = os.getenv(KAKAO_MAP_API_KEY) # check 
+  place_name = quote(place_name)
+  url = f'https://dapi.kakao.com/v2/local/search/keyword.{format}?query={place_name}&x={x}&y={y}&radius={radius}&size={size}&sort={sort}'
+  # KAKAO_MAP_API_KEY = "KakaoAK 4f55134dcdd4c80401cb0f0d73403f35"
+  headers = {"Authorization": KAKAO_MAP_API_KEY}
+  # print('api_json:\n',api_json,"\n")
+
+  
+  
+  try:
+    api_json = json.loads(str(requests.get(url,headers=headers).text))
+    result = api_json['documents'][0]
+  except IndexError as ie:
+    error_msg = f"KAKAO map keyword search api: no places were searched with query input: {place_name}"
+    logging.error(error_msg)
+    return "NO VALID INPUT"
+  except Exception as e:
+    error_msg = "KAKAO map keyword search api: Undefined error " + str(e)
+    logging.error(error_msg)
+    return "Undefined Error"
+
+  crd = {"lat": result['y'], "lng": result['x'], 'place_name': result['place_name'], 'road_address_name': result['road_address_name']} # 위도와 경도, 장소명, 도로명 주소 
+  return crd # 
+ 
+def parsing_tmap(data, from_place_name, to_place_name): # 이동 정보 를 넣으면
+    result = ''
+    # print("data:", data)
+    # 경로 정보 추출
+    itinerary = data['metaData']["plan"]["itineraries"][0]
+
+    # 1) 총 거리(km단위), 총 시간(시 단위 및 분 단위), 환승 횟수(지하철 및 버스 이용 횟수 포함), 총 요금(원 단위)
+    total_distance_km = itinerary["totalDistance"] / 1000
+    total_time_min = itinerary["totalTime"] / 60
+    total_time_hr = int(total_time_min // 60)
+    total_time_min = int(total_time_min % 60)
+    transfer_count = itinerary["transferCount"] + 1  # 환승 횟수는 지하철 및 버스 이용 횟수 포함
+    total_fare = itinerary["fare"]["regular"]["totalFare"]
+    
+    result = f'{from_place_name}에서 {to_place_name}까지 가는 길을 전달해드릴게요.\n'
+    result += '<요약>\n'
+    summary_text = (
+        f"총 소요 시간: {total_time_hr} 시간 {total_time_min} 분\n"
+        f"환승 횟수: {transfer_count} 회\n"
+        f"총 요금: {total_fare} 원\n\n"
+        f"이동 거리: {total_distance_km:.2f} km\n"
+        )
+    result += summary_text
+    
+
+    # 2) 상세 경로 안내
+    result += '상세 경로 안내\n'
+    route_description = ""
+    previous_end_name =f"{from_place_name}"
+    for leg in itinerary["legs"]:
+        if leg["mode"] == "WALK":
+            route_description += f"- {previous_end_name}부터 {leg['end']['name']}까지 {leg['sectionTime'] // 60}분 걸으세요.\n"
+        elif leg["mode"] == "SUBWAY":
+            #route_description += f"- {previous_end_name}에서 {leg['end']['name']}까지 {leg['Lane'][0]['route']}을 타고 {leg['sectionTime'] // 60}분 가세요.\n"
+            route_description += f"- {previous_end_name}에서 {leg['end']['name']}까지 {leg['route']}을 타고 {leg['sectionTime'] // 60}분 가세요.\n"
+        elif leg["mode"] == "BUS":
+            #bus_name = leg['route'].replace(":", ' ')
+            route_description += f"- {previous_end_name}에서 {leg['end']['name']}까지 {leg['route']} 버스를 타고 {leg['sectionTime'] // 60}분 가세요.\n"
+        previous_end_name = leg["end"]["name"]
+    result += route_description
+    return result
+
+
+def get_route_description(from_to, TMAP_API_KEY, KAKAO_MAP_API_KEY ):
+    from_str, to_str = from_to['from'], from_to['to']
+    """addresses = { # 추후 바꿔야함 
+        "home": "용산역",     #Replace with actual home address logic if available
+        "current": "사당역"  # Replace with actual current address logic if available
+        }
+    # from 
+    if from_str == 'home':
+        from_str = addresses['home']
+    elif from_str == 'current':
+        from_str =  addresses['current']
+    
+    # to
+    if to_str == 'home':
+        to_str = addresses['home']
+    elif to_str == 'current':
+        to_str =  addresses['current']
+        """
+    # 장소는 home, current, unknown 이 있을 수 있다. 
+    if 'unknown' in (from_str, to_str): # 목적지, 출발지가 제대로 입력되지 않은 경우 
+        return None
+    
+    # 경도 위도로 변환
+    from_cord = get_coord(from_str, KAKAO_MAP_API_KEY)
+    to_cord = get_coord(to_str, KAKAO_MAP_API_KEY)
+    if "NO VALID INPUT" in (from_cord, to_cord): # 에러 핸들링 
+        return "제대로된 출발지나 목적지가 입력되지 않았습니다. 다시 입력해주세요."
+    elif "Undefined Error" in (from_cord, to_cord): 
+        return "예기치 못한 에러가 발생했습니다. 다시 입력해주세요."
+    from_lat, from_lon = from_cord['lat'], from_cord['lng']
+    to_lat, to_lon = to_cord['lat'], to_cord['lng']
+    
+    route_intro_text = '' # 경로 안내 텍스트 
+    route_description = TMAP_API(from_lat, from_lon, to_lat, to_lon, TMAP_API_KEY) # 
+    if type(route_description) == str: # error 메시지 인경우 
+        print("다음 사유 때문에, 경로 탐색이 되지 않아요")
+        return f"다음 사유 때문에, 경로 탐색이 되지 않아요 : {route_description}. 다시 출발지와 목적지를 입력해주세요"
+    route_intro_text = parsing_tmap(route_description,from_cord['place_name'],to_cord['place_name'] )
+    return route_intro_text
\ No newline at end of file
Index: history.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/history.py b/history.py
new file mode 100644
--- /dev/null	
+++ b/history.py	
@@ -0,0 +1,60 @@
+from konlpy.tag import Okt
+from pymongo import MongoClient
+from datetime import datetime
+import pytz
+# KoNLPy를 사용하여 간단한 키워드 기반 태그 추출
+okt = Okt()
+
+def extract_tags(text):
+    # 명사만 추출
+    tags = okt.nouns(text)
+    return tags
+
+
+# MongoDB 연결 설정
+client = MongoClient('mongodb://localhost:27017/')
+db = client['chatbot_db']  # 데이터베이스 이름 설정
+collection = db['chat_history']  # 콜렉션 이름 설정
+
+def save_conversation(user_id, thread_id, role, text):
+    # 현재 시간을 한국 시간으로 설정
+    korea_tz = pytz.timezone('Asia/Seoul')
+    current_time = datetime.now(korea_tz).strftime('%Y-%m-%d %H:%M:%S')
+
+    # 대화 태그 추출
+    tags = extract_tags(text)
+
+    # 대화 내용 저장
+    conversation = {
+        "user_id": user_id,
+        "thread_id": thread_id,
+        "timestamp": current_time,
+        "role": role,
+        "text": text,
+        "tags": tags  # 태그 저장
+    }
+    collection.insert_one(conversation)
+
+def history(user_id, thread_id):
+    limit = 4
+    # 대화 기록 불러오기
+    query = {
+        "user_id": user_id,
+        "thread_id": thread_id
+    }
+    conversations = collection.find(query).sort("timestamp", -1).limit(limit)
+
+    # 내림차순으로 가져온 후, 이를 다시 뒤집어 최신순으로 반환
+    return list(conversations)[::-1]
+
+# 예시 사용
+save_conversation("user123", "thread456", "user", "안녕하세요, 오늘 날씨는 어떤가요?")
+save_conversation("user123", "thread456", "assistant", "안녕하세요! 오늘 날씨는 맑고 따뜻합니다.")
+
+# 최근 대화 5개 가져오기
+recent_conversations = history("user123", "thread456", limit=5)
+for conversation in recent_conversations:
+    print(f"대화 시간: {conversation['timestamp']}")
+    print(f"발화 주체: {conversation['role']}")
+    print(f"대화 텍스트: {conversation['text']}")
+    print(f"태그: {conversation['tags']}\n")
\ No newline at end of file
Index: evaluation/RAGAS.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/evaluation/RAGAS.py b/evaluation/RAGAS.py
new file mode 100644
--- /dev/null	
+++ b/evaluation/RAGAS.py	
@@ -0,0 +1,190 @@
+import pandas as pd
+import os
+from langchain.document_loaders import PyPDFLoader
+from langchain.text_splitter import RecursiveCharacterTextSplitter
+from langchain.prompts import PromptTemplate
+from langchain.chains import LLMChain
+from langchain_openai import ChatOpenAI, OpenAIEmbeddings
+from ragas.testset.generator import TestsetGenerator
+from ragas.testset.evolutions import simple, reasoning, multi_context
+from ragas import evaluate
+from datasets import Dataset
+from pdf_retriever import *
+from dotenv import load_dotenv
+from ragas.metrics import (
+    faithfulness,
+    answer_relevancy,
+    context_recall,
+    context_precision,
+)
+
+
+questions = ["What did the president say about Justice Breyer?", 
+             "What did the president say about Intel's CEO?",
+             "What did the president say about gun violence?",
+            ]
+ground_truths = [["The president said that Justice Breyer has dedicated his life to serve the country and thanked him for his service."],
+                ["The president said that Pat Gelsinger is ready to increase Intel's investment to $100 billion."],
+                ["The president asked Congress to pass proven measures to reduce gun violence."]]
+answers = []
+contexts = []
+
+
+load_dotenv() # .env 파일에서 환경 변수를 로드합니다
+OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY") # API 키 설정
+MODEL_VERSION = "gpt-4o-mini" # "gpt-3.5-turbo"  
+pdf_path = "data/ktb_data_08.pdf"
+
+
+# RAG를 위한 vectorDB와 qa chain 을 로드함. 
+documents = load_pdf(pdf_path)
+splitted_docs = split_docs(documents)
+db = vectorDB(OPENAI_API_KEY)
+db.add_documents(splitted_docs)
+retriever = db.as_retriever(search_kwargs={"k": 1}) # 유사도가 높은 결과 1개 반환 
+
+rag_chain = pdf_retriever(pdf_path, MODEL_VERSION, OPENAI_API_KEY)
+
+# Inference
+for query in questions:
+    answers.append(rag_chain.invoke(query))
+    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])
+
+# To dict
+data = {
+    "question": questions,
+    "answer": answers,
+    "contexts": contexts,
+    "ground_truths": ground_truth
+}
+
+
+# Convert dict to dataset
+dataset = Dataset.from_dict(data)
+
+
+result = evaluate(
+    dataset = dataset, 
+    metrics=[
+        context_precision,
+        context_recall,
+        faithfulness,
+        answer_relevancy,
+    ]
+)
+
+df = result.to_pandas()
+
+
+
+"""from ragas.metrics import (
+    faithfulness,
+    answer_relevancy,
+    answer_correctness,
+    context_recall,
+    context_precision,
+)
+
+
+
+class TestQaGenerator: # 질문과 정답 답변을 생성함. 
+    def __init__(self, pdf_path, api_key):
+        self.pdf_path = pdf_path
+        self.model_version = "gpt-4o-mini"
+        self.api_key = api_key
+
+    def load_and_split_document(self, split_chunk_size = None):
+        # Load the PDF document
+        loader = PyPDFLoader(self.pdf_path)
+        documents = loader.load()
+
+        # Split the document into chunks
+        text_splitter = RecursiveCharacterTextSplitter(
+            separators=["Title", "\n\n", ".", " "],  # Title, 문단, 문장, 단어 순으로 분할
+            chunk_size=500,  # 각 청크의 최대 크기
+            chunk_overlap=20  # 청크 간 중복되는 문자 수
+        )
+        docs = text_splitter.split_documents(documents)
+        
+        if split_chunk_size is None:
+            return docs
+        else:
+            return docs[:split_chunk_size]
+        #return docs
+
+    def generate_testset(self, test_size=10):
+
+
+        # generator with openai models
+        generator_llm = ChatOpenAI(model=self.model_version) #, api_key=self.api_key)
+        critic_llm = ChatOpenAI(model=self.model_version) # , api_key=self.api_key)
+        embeddings = OpenAIEmbeddings()
+
+        generator = TestsetGenerator.from_langchain(
+            generator_llm, 
+            critic_llm,
+            embeddings
+        )
+
+        splitted_docs = self.load_and_split_document(split_chunk_size = 15) # chunk size 조절하기.. test
+        distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25}
+        
+        # generate testset
+        testset = generator.generate_with_langchain_docs(splitted_docs, test_size=test_size, distributions =distributions) # 수정 test_size
+        # Print the generated test set
+        print("point2")
+        test_df = testset.to_pandas()
+        return test_df
+
+# TEST
+if __name__ == "__main__":
+
+    # 질문 만들기 데이터 만들기 
+    pdf_path = "data/ktb_data_08.pdf"  # Replace with your actual PDF file path
+    load_dotenv() # .env 파일에서 환경 변수를 로드합니다
+    OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY") # API 키 설정
+
+    testset_generator = TestQaGenerator(pdf_path, api_key=OPENAI_API_KEY)
+    test_df = testset_generator.generate_testset(test_size=5) # test_size  : 질문 개수 
+    questions = test_df["question"].values.tolist()
+    ground_truths = test_df["ground_truth"].values.tolist()
+    source_documents = test_df["contexts"].values.tolist()
+
+    # 평가하기 
+    answers = [] # RAG chain 답변
+    contexts = []
+    
+    # RAG 모델 정의 
+    MODEL_VERSION = "gpt-4o-mini" # "gpt-3.5-turbo"  
+    rag_chain = pdf_retriever(pdf_path, MODEL_VERSION, OPENAI_API_KEY)
+
+    test_df.to_csv("test.csv")
+    questions = ["국민취업제도 설명해줘", "어쩌라고" ] 
+    for question in questions:
+        response = rag_chain.invoke({"query": question})
+
+        print('response type:', response)
+        answers.append(response['result'])
+    
+
+        
+    response_dataset = Dataset.from_dict({
+        "question": questions,
+        "answer" : answers,
+        "contexts" : contexts,
+        "ground_truth" : ground_truths
+    })
+
+    # 평가 
+    metrics = [ faithfulness,
+                context_recall,
+                context_precision,
+                answer_correctness ]
+
+    result = evaluate(
+        response_dataset, 
+        metrics = metrics
+        )
+    result_df = result.to_pandas()
+    result_df.to_csv('result.csv')"""
+
Index: prev/pdf_retriever.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/prev/pdf_retriever.py b/prev/pdf_retriever.py
new file mode 100644
--- /dev/null	
+++ b/prev/pdf_retriever.py	
@@ -0,0 +1,101 @@
+
+# langchain 라이브러리에서 필요한 모듈들을 가져옵니다.
+import os
+from langchain.text_splitter import RecursiveCharacterTextSplitter
+#from langchain.chat_models import ChatOpenAI
+from langchain_community.chat_models import ChatOpenAI
+from langchain.chains import RetrievalQA
+from langchain.document_loaders import TextLoader
+from collections import Counter
+from langchain.document_loaders import PyMuPDFLoader  # PDF 파일을 읽어오는 데 사용
+from langchain.embeddings import OpenAIEmbeddings  # OpenAI의 임베딩 기능을 사용
+from langchain.text_splitter import SpacyTextSplitter  # 텍스트를 적절한 크기로 나누기
+from langchain.vectorstores import Chroma  
+from openai import OpenAIError# 벡터 데이터를 저장하고 검색하는 데 사용
+from dotenv import load_dotenv
+
+
+
+def load_pdf(file_path): # 파일을 읽어 문서 데이터를 가져옵니다.
+    loader = PyMuPDFLoader(file_path) # 클래스 정의 
+    documents = loader.load()  
+    print(f"Loaded {len(documents)} documents from the PDF.")
+    return documents
+
+
+def split_docs(documents):
+    text_splitter = RecursiveCharacterTextSplitter(
+        separators=["Title", "\n\n", "."],  # Title, 문단, 문장, 단어 순으로 분할
+        chunk_size=500,  # 각 청크의 최대 크기
+        chunk_overlap=50  # 청크 간 중복되는 문자 수
+    ) # test 용 
+    splitted_documents = text_splitter.split_documents(documents)  # 문서를 나눕니다.
+    print(f"Split into {len(splitted_documents)} document chunks.")
+    return splitted_documents
+
+def vectorDB(api_key): # vectorDB 생성
+    # OpenAI의 임베딩 모델을 초기화합니다. 여기서는 'text-embedding-ada-002' 모델을 사용합니다.
+    embedding_function = OpenAIEmbeddings(
+        model= "text-embedding-3-small", #"text-embedding-3-large", "text-embedding-ada-002",
+        openai_api_key=api_key
+    )
+    db = None
+    if os.path.exists("data/chroma.db"): # 이전에 존재한 경우 
+        print("이미 벡터 db 존재")
+        db = Chroma(persist_directory="data/chroma.db", embedding_function=embedding_function)
+    else:
+        print("새롭게 만들기")
+        db = Chroma(
+            persist_directory="data/chroma.db",  # 데이터 저장 경로 지정
+            embedding_function=embedding_function  # 임베딩 함수 지정
+        )
+    return db 
+
+
+def create_qa_chain(retriever, model_name, api_key):
+    """Create a QA chain using the retriever."""
+    rag_chain = RetrievalQA.from_chain_type(
+        llm=ChatOpenAI(model_name=model_name, temperature=0,
+                       openai_api_key=api_key),
+        chain_type="stuff", #stuff,  map_reduce, refine, map_rerank
+        retriever=retriever,
+        return_source_documents=False,
+        chain_type_kwargs = {
+        "document_separator": "<<<<>>>>>"
+        }
+    )
+    return rag_chain
+
+
+def pdf_retriever(pdf_path, model_version, OPENAI_API_KEY): #, open_api_key): # test
+    open_api_key = OPENAI_API_KEY # API 키 설정
+    # RAG를 위한 vectorDB와 qa chain 을 로드함. 
+    documents = load_pdf(pdf_path)
+    splitted_docs = split_docs(documents)
+    db = vectorDB(open_api_key)
+    db.add_documents(splitted_docs)
+    retriever = db.as_retriever(search_kwargs={"k": 1}) # 유사도가 높은 결과 1개 반환 
+    rag_chain = create_qa_chain(retriever, model_version, open_api_key)
+    return rag_chain
+
+"""
+## ==== test ===========
+if __name__ == "__main__":
+    open_api_key = os.environ.get("OPENAI_API_KEY") # API 키 설정
+    pdf_path = './data/data.pdf' # PDF 경로를 지정해주기 -
+
+    documents = load_pdf(pdf_path)
+    vectordb = vectorDB(documents, open_api_key)
+    model_version = "gpt-3.5-turbo"
+
+    # QA 체인 생성 및 쿼리 
+    retriever = vectordb.as_retriever(search_kwargs={"k": 1}) # 유사도가 높은 결과 1개 반환 
+    qa_chain = create_qa_chain(retriever, open_api_key)
+    # input_text = "문재인 대통령 취임은 언제야?"
+    input_text = "오늘 판교 날씨 알려줘"
+    response = query_qa_chain(qa_chain, input_text, model_version)
+    print('결과: ', response)
+    #documents = retriever.get_relevant_documents("현충일 제정일이 언제야??")
+
+## ==== test ===========
+"""
Index: test/input/user_inputs.json
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/test/input/user_inputs.json b/test/input/user_inputs.json
new file mode 100644
--- /dev/null	
+++ b/test/input/user_inputs.json	
@@ -0,0 +1,23 @@
+{
+  "user_inputs": [
+    "카카오 클라우드 교육 채널에 로그인이 되지 않을 경우 어떻게 해야 하나요?",
+    "카카오 클라우드 교육의 전체 일정과 내용은 어떻게 구성되어 있나요?",
+    "카카오 클라우드 교육의 시간과 장소는 어떻게 되나요?",
+    "카카오 클라우드 교육의 방식은 어떻게 어떻게 되나요?",
+
+    "카카오 부트캠프 가는 길 알려줘",
+    "카카오 부트캠프 교육장 주소는 어떻게 되나요?",
+    "카카오 부트캠프 교육장 주차 지원이 되나요?",
+    "카카오 부트캠프 가는 길 알려줘",
+
+    "ChatGPT Plus 구독료 지원 방법 안내해줘",
+    "ChatGPT Plus 구독료 지원을 신청하는 방법은 무엇인가요?",
+    "ChatGPT Plus 구독료 지원 대상과 횟수에 대해서 안내해줘",
+    "ChatGPT Plus 구독료 청구 방법에 대해서 알려줘",
+    "chatgpt plus 구독료 청구할 때, 증빙자료에 뭐 들어가야해?",
+    "chatgpt plus 구독료 청구할 때, 유의 사항에 대해서 알려줘"
+
+
+  ]
+}
+
Index: mongoDBjson.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/mongoDBjson.py b/mongoDBjson.py
new file mode 100644
--- /dev/null	
+++ b/mongoDBjson.py	
@@ -0,0 +1,29 @@
+import json
+from bson import ObjectId
+from pymongo import MongoClient
+
+# MongoDB에 연결
+client = MongoClient('mongodb://localhost:27017/')
+db = client['chatbot_db']
+collection = db['chat_history']
+
+# 모든 데이터를 가져오기
+data = list(collection.find())
+
+# ObjectId를 문자열로 변환하는 함수
+def convert_objectid(data):
+    if isinstance(data, list):
+        return [convert_objectid(item) for item in data]
+    elif isinstance(data, dict):
+        return {key: convert_objectid(value) for key, value in data.items()}
+    elif isinstance(data, ObjectId):
+        return str(data)
+    else:
+        return data
+
+# 데이터를 변환
+data = convert_objectid(data)
+
+# JSON 파일로 저장
+with open('output.json', 'w', encoding='utf-8') as file:
+    json.dump(data, file, ensure_ascii=False, indent=4)
\ No newline at end of file
Index: logging/logger_config.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/logging/logger_config.py b/logging/logger_config.py
new file mode 100644
--- /dev/null	
+++ b/logging/logger_config.py	
@@ -0,0 +1,40 @@
+import logging
+import traceback
+import sys
+
+class CustomFormatter(logging.Formatter):
+    def formatException(self, exc_info):
+        """예외 정보를 포맷합니다."""
+        tb_str = traceback.format_exception(*exc_info)
+        return ''.join(tb_str).strip()  # 포맷을 깔끔하게 정리합니다.
+    
+    def format(self, record):
+        """로그 메시지 포맷을 정의합니다."""
+        # 기본 로그 메시지
+        log_message = super().format(record)
+        
+        # 예외 메시지와 커스텀 메시지 생성
+        exception_message = f"{{{record.exc_info[1]}}}" if record.exc_info else ''
+        custom_message = f"{{나의 커스텀 로그}} - {exception_message}".strip()
+        
+        # 포맷 조정
+        return (f"{record.asctime} {record.levelname} - {record.pathname} > line {record.lineno} "
+                f"in {record.funcName}() \n{custom_message}\n{record.msg}")
+
+def setup_custom_logger(name):
+    """커스텀 로거를 설정합니다."""
+    logger = logging.getLogger(name)
+    logger.setLevel(logging.ERROR)
+    
+    # 파일 핸들러 설정
+    file_handler = logging.FileHandler('error.log')
+    file_handler.setLevel(logging.ERROR)
+    
+    # 포맷터 설정
+    formatter = CustomFormatter('%(asctime)s %(levelname)s - %(pathname)s > line %(lineno)d in %(funcName)s() \n%(message)s')
+    file_handler.setFormatter(formatter)
+    
+    # 핸들러 추가
+    logger.addHandler(file_handler)
+    
+    return logger
Index: get_weather.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/get_weather.py b/get_weather.py
new file mode 100644
--- /dev/null	
+++ b/get_weather.py	
@@ -0,0 +1,110 @@
+import json
+import os 
+import requests
+from dotenv import load_dotenv
+import logging
+
+
+logging.basicConfig(
+    filename='./logging/error_log.log',
+    level=logging.INFO,
+    format='%(asctime)s - %(levelname)s - %(message)s',
+    datefmt='%Y-%m-%d %H:%M:%S'
+)
+
+def weather_api():
+    # 환경 변수 받아오기
+    load_dotenv()
+    WEATHER_API_KEY = os.environ.get("WEATHER_API_KEY")
+    LOCATION = os.environ.get("LOCATION1")
+    """# Print the values to verify they are correctly retrieved
+    print("WEATHER_API_KEY:", WEATHER_API_KEY)
+    print("LOCATION:", LOCATION)"""
+    
+
+    if not WEATHER_API_KEY or not LOCATION: # WEATHER_API_KEY와 LOCATION이 로딩 안됐을 때
+        logging.error('API key or location is not loaded')
+        return {'error': 'API key or location is not set in environment variables.'}
+    
+    # 날씨 API 요청하기
+    base_url = f'http://api.openweathermap.org/data/2.5/weather?q={LOCATION}&appid={WEATHER_API_KEY}&units=metric'
+    #print("base_url:", base_url)
+    
+    try:
+        response = requests.post(base_url) 
+        response = response.json()
+        if response['cod'] != 200:
+            logging.error(f"open weather map api err code: {response['cod']}, err msg {response['message']}\n - WEATHER_API_KEY:{WEATHER_API_KEY}, LOCATION:{LOCATION} ")
+            return {f'error': f"err code: {response['cod']}, err msg: {response['message']}"}
+        #return response.json()
+        return response
+        
+    except requests.exceptions.HTTPError as http_err:
+        return {'error': f'HTTP error occurred: {http_err}'}
+    except Exception as err:
+        return {'error': f'Other error occurred: {err}'}
+
+def weather_data_prompt(data): # data는 json 형식으로 날씨 정보를 담고 있음. 
+    # overview of weather - data의 weather 오브젝트에 관련 정보가 있음. 
+    main_weather_info = "주요 기상 상태:  "
+    #print("weather data", data)
+    for weather in data['weather']:
+        weather_main = weather['main']
+        weather_description = weather['description']
+        main_weather_info += f"{weather_main}:{weather_description}. "
+    main_weather_info += '\n'
+
+    # 디테일한 정보 
+    temp_celsius = data['main']['temp']
+    feels_like_celsius = data['main']['feels_like'] # 체감 온도
+    pressure = data['main']['pressure']
+    humidity = data['main']['humidity']
+    wind_speed = data['wind']['speed']
+    clouds_all = data['clouds']['all']
+    rain_1h = data.get('rain', {}).get('1h', 0) # 지난 1시간의 rain 강수량, 없으면 0 리턴 
+    snow_1h = data.get('snow', {}).get('1h', 0)
+
+    # Create the desired string
+
+    detailed_weather_info = (
+        f"세부 정보: "
+        f"온도: {temp_celsius:.2f}°C,"
+        f"체감 온도: {feels_like_celsius:.2f}°C,"
+        f"기압: {pressure} hPa,"
+        f"습도: {humidity}%,"
+        f"풍속: {wind_speed} m/s,"
+        f"구름 양: {clouds_all}%,"
+    )
+    if rain_1h > 0:
+        detailed_weather_info += f"강우량(지난 1시간): {rain_1h} mm,"
+    if snow_1h > 0:
+        detailed_weather_info += f"강설량(지난 1시간): {snow_1h} mm,"
+
+    # Print the weather information
+    result = main_weather_info+detailed_weather_info
+    return result
+
+def get_weather_info():
+    data = weather_api() # API를 통해서 날씨 정보 받아옴, json 형식  
+    #print("weather api key data:", data)
+    if 'error' in data.keys(): # API 키와 LOCATION이 환경 변수 파일에서 잘 로드가 안됨 
+        # logging 
+        prompt = "죄송해요, 시스템 오류가 있어요. 다시 말해줄래요? "
+    else: 
+        prompt = weather_data_prompt(data) #필요한 정보만 받아서, prompt로 생성 
+    return prompt
+
+
+
+
+
+"""
+# TEST 
+if __name__ == "__main__":
+    json = get_weather_info()
+    #json = {'coord': {'lon': 21.0118, 'lat': 52.2298}, 'weather': [{'id': 500, 'main': 'Clouds', 'description': 'light cloud', 'icon': '10d'}, {'id': 500, 'main': 'Rain', 'description': 'light rain', 'icon': '10d'}], 'base': 'stations', 'main': {'temp': 291.1, 'feels_like': 291.01, 'temp_min': 289.62, 'temp_max': 292.51, 'pressure': 1009, 'humidity': 79, 'sea_level': 1009, 'grnd_level': 995}, 'visibility': 10000, 'wind': {'speed': 4.47, 'deg': 20, 'gust': 0}, 'rain': {'1h': 0.11}, 'clouds': {'all': 100}, 'dt': 1722668540, 'sys': {'type': 2, 'id': 2092919, 'country': 'PL', 'sunrise': 1722654022, 'sunset': 1722709427}, 'timezone': 7200, 'id': 756135, 'name': 'Warsaw', 'cod': 200}
+    print(parsing_weather_info(json))"""
+
+
+
+
diff --git a/evaluation/RAGAS_2.py b/evaluation/RAGAS_2.py
new file mode 100644
