Index: etc/error_handler_test/chatgpt_api.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import openai\nimport json\nimport logging\nimport warnings\nimport os\nfrom flask import Flask, request, jsonify, Response, abort\nfrom dotenv import load_dotenv\nfrom openai import OpenAIError\n\n\n# 로깅 설정\nlogging.basicConfig(\n    filename='./logging/error_log.log',\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    datefmt='%Y-%m-%d %H:%M:%S'\n)\n\n\nload_dotenv() # # .env 파일에서 환경 변수를 로드합니다\nOPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY2\") # API 키 설정\nMAX_TOKENS_OUTPUT = 600\nMODEL_VERSION = \"gpt-4o\" # \"gpt-3.5-turbo\"  \n\ndef stream_chatgpt(system_prompt, user_prompt):\n    client = openai.OpenAI(api_key=OPENAI_API_KEY)\n    try:\n        response = client.chat.completions.create(\n            model=MODEL_VERSION,\n            messages=[\n                {\"role\": \"system\", \"content\": system_prompt},\n                {\"role\": \"user\", \"content\": user_prompt}\n            ],\n            temperature=0.0, # 출력의 다양성 조절 (0~1), 높을 수록 창의적인 대답\n            max_tokens= MAX_TOKENS_OUTPUT, # 최대 출력 토큰 개수 \n            n = 1,         # 생성 답변 개수,\n            stream=True\n        )\n        def event_stream(): #stream generator\n            print(\"response\", response)\n            for chunk in response:\n                text = chunk.choices[0].delta.get('content')\n                if len(text):\n                    yield text\n                    print(text)\n        return Response(event_stream(), mimetype='text/event-stream')\n    except Exception as e:\n        print(f\"Error while calling chatGPT API function call: {str(e)}\")\n        logging.error(f\"Error while calling chatGPT API function call: {str(e)}\")\n        abort(500)\n        # return None\n    \n# 동기식 chatGPT 함수\ndef cls_chatgpt(system_prompt, user_prompt):\n    client = openai.OpenAI(api_key=OPENAI_API_KEY)\n    try:\n        response = client.chat.completions.create(\n            model=MODEL_VERSION,\n            messages=[\n                {\"role\": \"system\", \"content\": system_prompt},\n                {\"role\": \"user\", \"content\": user_prompt}\n            ],\n            temperature=0.0, # 출력의 다양성 조절 (0~1), 높을 수록 창의적인 대답\n            max_tokens= MAX_TOKENS_OUTPUT, # 최대 출력 토큰 개수 \n            n = 1,         # 생성 답변 개수,\n            stream=True\n        )\n        return response.choices[0].message.content\n    except Exception as e:\n        print(f\"Error while calling chatGPT API function call: {str(e)}\")\n        logging.error(f\"Error while calling chatGPT API function call: {str(e)}\")\n        raise e # OpenAIError\n    \n\n\"\"\"def test():\n    system_prompt = \"you are a helpful assistant \"\n    user_prompt = \"한국 전래 동화 3개만 알려줘\"\n    stream_chatgpt(system_prompt, user_prompt)\n\ntest()\n\"\"\"\n    \n\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/etc/error_handler_test/chatgpt_api.py b/etc/error_handler_test/chatgpt_api.py
--- a/etc/error_handler_test/chatgpt_api.py	(revision a46b3f9d74c95c3162762e0e6fb8c0575eeee7d5)
+++ b/etc/error_handler_test/chatgpt_api.py	(date 1727342579750)
@@ -45,9 +45,8 @@
                     print(text)
         return Response(event_stream(), mimetype='text/event-stream')
     except Exception as e:
-        print(f"Error while calling chatGPT API function call: {str(e)}")
         logging.error(f"Error while calling chatGPT API function call: {str(e)}")
-        abort(500)
+        raise e # OpenAIError
         # return None
     
 # 동기식 chatGPT 함수
@@ -67,7 +66,6 @@
         )
         return response.choices[0].message.content
     except Exception as e:
-        print(f"Error while calling chatGPT API function call: {str(e)}")
         logging.error(f"Error while calling chatGPT API function call: {str(e)}")
         raise e # OpenAIError
     
